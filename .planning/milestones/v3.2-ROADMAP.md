# Milestone v3.2: Evaluation Harness

**Status:** ✅ SHIPPED 2026-01-30
**Phases:** 35-39
**Total Plans:** 16

## Overview

Build eval/ — a standalone harness that injects chaos, monitors agent problem-solving, grades performance, and provides historical analysis.

## Phases

### Phase 35: Runner Layer
**Goal**: Developer can run single-trial evaluations and see raw results stored in database

**Depends on**: Nothing (first phase of v3.2)

**Requirements**: RUN-01, RUN-02, RUN-03, RUN-04, RUN-05, RUN-06, SUBJ-01, SUBJ-02, SUBJ-03, CLI-01, CLI-02

**Success Criteria**:
  1. Developer can run `eval run --subject tikv --chaos node_kill` and trial executes
  2. Developer can run `eval run --baseline` and trial executes without agent
  3. Trial data persists in eval.db with timing data
  4. Trial data includes subject state before/after chaos and commands extracted from agent session
  5. TiKVEvalSubject implements EvalSubject protocol

Plans:
- [x] 35-01-PLAN.md — Package foundation with EvalSubject protocol and core types
- [x] 35-02-PLAN.md — TiKVEvalSubject with Docker Compose lifecycle and node_kill chaos
- [x] 35-03-PLAN.md — Database layer and campaign runner harness
- [x] 35-04-PLAN.md — CLI with run command for single-trial execution

---

### Phase 36: Analysis Layer
**Goal**: Developer can compute scores and compare performance across trials/campaigns

**Depends on**: Phase 35

**Requirements**: ANAL-01, ANAL-02, ANAL-03, ANAL-04, ANAL-05, ANAL-06, CLI-04, CLI-05, CLI-06

**Success Criteria**:
  1. Developer can run `eval analyze <campaign_id>` and see scores
  2. Developer can run `eval compare-baseline <campaign_id>` and see agent vs self-healing
  3. Developer can run `eval compare <campaign_a> <campaign_b>` and see differences
  4. Analysis computes command metrics (count, unique, thrashing, destructive)
  5. Analysis is idempotent

Plans:
- [x] 36-01-PLAN.md — Analysis types and scoring module (ANAL-01, ANAL-06)
- [x] 36-02-PLAN.md — Command analysis with LLM classification (ANAL-02, ANAL-03)
- [x] 36-03-PLAN.md — Baseline and campaign comparison (ANAL-04, ANAL-05)
- [x] 36-04-PLAN.md — CLI commands analyze, compare, compare-baseline (CLI-04, CLI-05, CLI-06)

---

### Phase 37: Viewer Layer
**Goal**: Developer can browse campaigns and drill into trial details via CLI and web UI

**Depends on**: Phase 36

**Requirements**: VIEW-01, VIEW-02, VIEW-03, VIEW-04, VIEW-05

**Success Criteria**:
  1. Developer can run `eval list` and see all campaigns
  2. Developer can run `eval show <campaign_id>` and see campaign summary
  3. Developer can run `eval show <trial_id>` and see trial detail
  4. Developer can open web UI and browse campaigns/trials
  5. Web UI displays trial reasoning and commands

Plans:
- [x] 37-01-PLAN.md — CLI list and show commands (VIEW-01, VIEW-02, VIEW-03)
- [x] 37-02-PLAN.md — Web viewer with FastAPI, templates, reasoning display (VIEW-04, VIEW-05)

---

### Phase 38: Chaos Expansion
**Goal**: Developer can run batch campaigns with multiple chaos types

**Depends on**: Phase 37

**Requirements**: SUBJ-04, SUBJ-05, SUBJ-06, CLI-03

**Success Criteria**:
  1. TiKV supports latency chaos (tc netem)
  2. TiKV supports disk pressure chaos (fallocate)
  3. TiKV supports network partition chaos (iptables)
  4. Developer can define campaign config YAML
  5. Developer can run `eval run campaign config.yaml`

Plans:
- [x] 38-01-PLAN.md — Chaos injection functions (latency, disk pressure, network partition)
- [x] 38-02-PLAN.md — Campaign YAML config and batch runner with parallel support

---

### Phase 39: Config Variants
**Goal**: Developer can test different agent configurations and compare performance

**Depends on**: Phase 38

**Requirements**: CONF-01, CONF-02, CONF-03

**Success Criteria**:
  1. Config variants define model, system_prompt, tools_config
  2. Campaign config can specify variant
  3. Analysis compares performance across variants
  4. Developer can see which configuration performs best

Plans:
- [x] 39-01-PLAN.md — Variant types, loading, and list-variants CLI
- [x] 39-02-PLAN.md — Campaign integration with variant field and database migration
- [x] 39-03-PLAN.md — Variant comparison analysis and compare-variants CLI
- [x] 39-04-PLAN.md — Gap closure: Wire variant config to agent execution

---

## Milestone Summary

**Key Decisions:**
- Standalone eval/ package separate from operator-core
- Protocol-based design (EvalSubject) for subject-agnostic testing
- Fresh operator.db per trial in managed mode for isolation
- Variant config flows through tickets table to agent

**Issues Resolved:**
- Managed operator mode now works end-to-end
- Timezone handling for cross-database timestamp comparisons
- Command extraction uses session_id instead of timestamp filtering

**Technical Debt Incurred:**
- Timing display shows negative values due to timezone offset mismatch (cosmetic)

---

*For current project status, see .planning/ROADMAP.md*
