---
phase: 18-docker-compose
plan: 02
type: execute
wave: 2
depends_on: ["18-01"]
files_modified:
  - docker/loadgen/loadgen.py
  - docker/loadgen/Dockerfile
  - docker/docker-compose.yml
autonomous: false

must_haves:
  truths:
    - "Load generator starts automatically when cluster is healthy"
    - "Load generator sends requests to all 3 nodes in round-robin"
    - "Traffic patterns include steady rate and burst spikes"
    - "Progress stats show requests sent, success/fail counts, current RPS"
  artifacts:
    - path: "docker/loadgen/loadgen.py"
      provides: "httpx-based traffic generator"
      contains: "itertools.cycle"
    - path: "docker/loadgen/Dockerfile"
      provides: "Container image for load generator"
      contains: "httpx"
  key_links:
    - from: "docker-compose.yml"
      to: "docker/loadgen/Dockerfile"
      via: "build context"
      pattern: "build:.*context:.*loadgen"
    - from: "loadgen service"
      to: "ratelimiter services"
      via: "depends_on with condition"
      pattern: "ratelimiter-[123]:.*condition: service_healthy"
    - from: "loadgen.py"
      to: "rate limit endpoints"
      via: "HTTP requests"
      pattern: "/check"
---

<objective>
Create load generator that produces configurable traffic patterns against the rate limiter cluster

Purpose: Enable testing and demonstration of the rate limiter cluster behavior under load, including steady traffic and burst patterns that can trigger rate limiting.

Output: Containerized load generator that runs in docker-compose, sending round-robin requests to all nodes with periodic stats output.
</objective>

<execution_context>
@/Users/jrtipton/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jrtipton/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/18-docker-compose/18-RESEARCH.md
@.planning/phases/18-docker-compose/18-CONTEXT.md
@.planning/phases/18-docker-compose/18-01-SUMMARY.md
@packages/ratelimiter-service/src/ratelimiter_service/api/rate_limit.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create load generator Python script</name>
  <files>docker/loadgen/loadgen.py</files>
  <action>
Create docker/loadgen/loadgen.py implementing an async load generator with httpx:

**Environment variables for configuration:**
- TARGETS: Comma-separated list of node URLs (default: "http://ratelimiter-1:8000,http://ratelimiter-2:8000,http://ratelimiter-3:8000")
- RPS: Requests per second (default: 10)
- DURATION: Test duration in seconds (default: 60, 0 for infinite)
- BURST_ENABLED: Enable burst patterns (default: true)
- BURST_MULTIPLIER: Burst RPS multiplier (default: 5)
- BURST_DURATION: Burst duration in seconds (default: 5)
- BURST_INTERVAL: Seconds between bursts (default: 30)

**Implementation pattern:**
1. Use asyncio + httpx.AsyncClient with Limits(max_connections=100) and Timeout(10.0)
2. itertools.cycle for round-robin target selection
3. asyncio.Semaphore(100) for concurrent request limiting
4. Stats dataclass tracking: requests, success (200/429), failed, start_time

**Traffic patterns:**
- Steady: Send requests at configured RPS using asyncio.sleep(1.0/rps)
- Burst: When burst_enabled, periodically send at BURST_MULTIPLIER * RPS for BURST_DURATION seconds

**Request format:**
- POST to {target}/check with JSON body: {"key": "loadgen-{uuid4()[:8]}", "limit": 100, "window_ms": 60000}
- Both 200 (allowed) and 429 (blocked) count as success (rate limiter working correctly)
- Connection errors and non-200/429 responses count as failed

**Stats output:**
- Print stats every 10 seconds: "Requests: N | Success: N | Failed: N | Blocked: N | RPS: X.X"
- Print "BURST MODE" when entering burst, "STEADY MODE" when returning to normal
- Final summary at end

**Graceful shutdown:**
- Handle SIGTERM/SIGINT for clean exit
- Await remaining in-flight requests before exiting
  </action>
  <verify>
python docker/loadgen/loadgen.py --help or running briefly locally confirms script syntax is valid
  </verify>
  <done>Load generator script handles steady and burst patterns with round-robin targeting and stats output</done>
</task>

<task type="auto">
  <name>Task 2: Create Dockerfile for load generator</name>
  <files>docker/loadgen/Dockerfile</files>
  <action>
Create docker/loadgen/Dockerfile:

```dockerfile
FROM python:3.11-slim-bookworm

WORKDIR /app

# Install httpx (only dependency needed)
RUN pip install --no-cache-dir httpx>=0.27.0

COPY loadgen.py .

# Use exec form for proper signal handling
CMD ["python", "loadgen.py"]
```

Keep it minimal - no curl needed (no healthcheck for loadgen), just httpx.
  </action>
  <verify>
docker build -t loadgen-test docker/loadgen/ should complete without errors
  </verify>
  <done>Dockerfile builds load generator image with httpx dependency</done>
</task>

<task type="auto">
  <name>Task 3: Add load generator service to docker-compose.yml</name>
  <files>docker/docker-compose.yml</files>
  <action>
Add loadgen service to docker/docker-compose.yml:

```yaml
  loadgen:
    build:
      context: ./loadgen
    environment:
      - TARGETS=http://ratelimiter-1:8000,http://ratelimiter-2:8000,http://ratelimiter-3:8000
      - RPS=${LOADGEN_RPS:-10}
      - DURATION=${LOADGEN_DURATION:-0}
      - BURST_ENABLED=${LOADGEN_BURST_ENABLED:-true}
      - BURST_MULTIPLIER=${LOADGEN_BURST_MULTIPLIER:-5}
      - BURST_DURATION=${LOADGEN_BURST_DURATION:-5}
      - BURST_INTERVAL=${LOADGEN_BURST_INTERVAL:-30}
    depends_on:
      ratelimiter-1:
        condition: service_healthy
      ratelimiter-2:
        condition: service_healthy
      ratelimiter-3:
        condition: service_healthy
    restart: "no"
    networks:
      - ratelimiter
```

Also update docker/.env.example to include load generator configuration variables:
```
# Load Generator Configuration
LOADGEN_RPS=10
LOADGEN_DURATION=0
LOADGEN_BURST_ENABLED=true
LOADGEN_BURST_MULTIPLIER=5
LOADGEN_BURST_DURATION=5
LOADGEN_BURST_INTERVAL=30
```
  </action>
  <verify>
cd docker && docker compose config validates with loadgen service included
  </verify>
  <done>docker-compose.yml includes loadgen service with configurable traffic parameters</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete Docker Compose environment with Redis, 3 rate limiter nodes, Prometheus, and load generator</what-built>
  <how-to-verify>
1. Start the stack: `cd docker && docker compose up -d`
2. Wait for services to be healthy: `docker compose ps` (all should show "healthy" or "running")
3. Check Prometheus targets: Open http://localhost:9090/targets
   - Expected: 3 ratelimiter targets all showing "UP"
4. View load generator logs: `docker compose logs -f loadgen`
   - Expected: Periodic stats output showing requests, success, failed counts
   - Expected: Burst mode announcements every ~30 seconds
5. Check rate limiter metrics: Open http://localhost:8001/metrics
   - Expected: Prometheus metrics including ratelimiter_requests_checked_total
6. Clean up: `docker compose down`
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues</resume-signal>
</task>

</tasks>

<verification>
After all tasks complete:
1. Loadgen builds: `docker build -t loadgen docker/loadgen/`
2. Full stack starts: `cd docker && docker compose up -d`
3. All services running: `docker compose ps` shows 6 services (redis, 3 ratelimiters, prometheus, loadgen)
4. Loadgen produces traffic: `docker compose logs loadgen` shows periodic stats
5. Rate limiters receive traffic: Check /metrics on any node shows increasing request counts
6. Prometheus scrapes all: http://localhost:9090/targets shows all UP
</verification>

<success_criteria>
- Load generator sends round-robin requests to all 3 nodes
- Burst patterns occur periodically (5x RPS for 5s every 30s by default)
- Stats output shows requests, success, failed, blocked counts
- Traffic is configurable via environment variables
- Human verification confirms end-to-end functionality
</success_criteria>

<output>
After completion, create `.planning/phases/18-docker-compose/18-02-SUMMARY.md`
</output>
