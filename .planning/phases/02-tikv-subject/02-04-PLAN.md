---
phase: 02-tikv-subject
plan: 04
type: tdd
wave: 2
depends_on: ["02-01"]
files_modified:
  - packages/operator-tikv/src/operator_tikv/log_parser.py
  - packages/operator-tikv/tests/test_log_parser.py
  - packages/operator-tikv/src/operator_tikv/__init__.py
autonomous: true

must_haves:
  truths:
    - "parse_log_line() extracts timestamp, level, source, message, fields from TiDB log format"
    - "extract_leadership_changes() filters for leadership-related log events"
    - "Log parser handles malformed lines gracefully (returns None)"
    - "Leadership changes include region_id when present"
  artifacts:
    - path: "packages/operator-tikv/src/operator_tikv/log_parser.py"
      provides: "Log parsing functions and types"
      contains: "def parse_log_line"
      min_lines: 60
    - path: "packages/operator-tikv/tests/test_log_parser.py"
      provides: "Tests for log parsing"
      contains: "def test_"
      min_lines: 50
  key_links:
    - from: "packages/operator-tikv/src/operator_tikv/log_parser.py"
      to: "TiDB unified log format"
      via: "regex pattern"
      pattern: "LOG_PATTERN.*compile"
---

<objective>
Implement the TiKV log parser using TDD for TIKV-04 requirement.

Purpose: Log parser extracts leadership change events for AI diagnosis context. Per CONTEXT.md, logs are for diagnosis context only (not independent alerting).

Output: Tested log parser that extracts structured events from TiKV log lines.
</objective>

<execution_context>
@/Users/jrtipton/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jrtipton/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/02-tikv-subject/02-CONTEXT.md
@.planning/phases/02-tikv-subject/02-RESEARCH.md
</context>

<feature>
  <name>TiKV Log Parser</name>
  <files>
    packages/operator-tikv/src/operator_tikv/log_parser.py
    packages/operator-tikv/tests/test_log_parser.py
  </files>
  <behavior>
Log parser handles TiDB unified log format per RESEARCH.md Pattern 3.

Format: `[timestamp] [LEVEL] [source] [message] [field=value]...`
Example: `[2024/01/15 14:20:11.015 +08:00] [INFO] [raftstore] [leader changed] [region_id=123]`

Types:
- `LogEntry`: Parsed log line with timestamp, level, source, message, fields dict
- `LeadershipChange`: Leadership event with timestamp, region_id, message

Functions:
- `parse_log_line(line: str) -> LogEntry | None`: Parse single line, None if malformed
- `extract_leadership_changes(lines: list[str]) -> list[LeadershipChange]`: Filter for leadership events

Per CONTEXT.md decisions:
- Event types: leadership changes only (simplest viable)
- Purpose: context for AI diagnosis, not alerting
- Match keywords: "transfer leader", "leader changed", "became leader", "step down", "leader election"

Per RESEARCH.md Pitfall 5:
- Parse timezone from log format for accurate timestamps
- For Phase 2, use naive datetime (timezone handling can be added later if needed)

Test cases:
- parse_log_line with valid INFO line -> returns LogEntry with all fields
- parse_log_line with fields -> extracts field=value pairs into dict
- parse_log_line with empty/malformed line -> returns None
- extract_leadership_changes filters only leadership keywords
- extract_leadership_changes extracts region_id from fields
- extract_leadership_changes handles lines without region_id (skips them)
  </behavior>
  <implementation>
```python
import re
from dataclasses import dataclass
from datetime import datetime

# TiDB unified log format regex (from RESEARCH.md)
LOG_PATTERN = re.compile(
    r'\[(\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2}\.\d{3} [+-]\d{2}:\d{2})\] '  # timestamp
    r'\[(\w+)\] '  # level
    r'\[([^\]]+)\] '  # source
    r'\[([^\]]*)\]'  # message
    r'(.*)?$'  # optional fields
)

FIELD_PATTERN = re.compile(r'\[(\w+)=([^\]]+)\]')

LEADERSHIP_KEYWORDS = [
    "transfer leader",
    "leader changed",
    "became leader",
    "step down",
    "leader election"
]

@dataclass
class LogEntry:
    """Parsed TiKV log line."""
    timestamp: datetime
    level: str
    source: str
    message: str
    fields: dict[str, str]

@dataclass
class LeadershipChange:
    """Leadership change event extracted from logs."""
    timestamp: datetime
    region_id: int
    message: str

def parse_log_line(line: str) -> LogEntry | None:
    """Parse a TiKV log line into structured data."""
    if not line or not line.strip():
        return None

    match = LOG_PATTERN.match(line.strip())
    if not match:
        return None

    timestamp_str, level, source, message, fields_str = match.groups()

    # Parse timestamp (ignore timezone for Phase 2 simplicity)
    try:
        timestamp = datetime.strptime(timestamp_str[:23], "%Y/%m/%d %H:%M:%S.%f")
    except ValueError:
        return None

    # Parse fields
    fields: dict[str, str] = {}
    if fields_str:
        for field_match in FIELD_PATTERN.finditer(fields_str):
            fields[field_match.group(1)] = field_match.group(2)

    return LogEntry(
        timestamp=timestamp,
        level=level,
        source=source,
        message=message,
        fields=fields
    )

def extract_leadership_changes(lines: list[str]) -> list[LeadershipChange]:
    """Extract leadership change events from log lines."""
    changes: list[LeadershipChange] = []

    for line in lines:
        # Quick keyword check before full parsing
        line_lower = line.lower()
        if not any(kw in line_lower for kw in LEADERSHIP_KEYWORDS):
            continue

        entry = parse_log_line(line)
        if entry is None:
            continue

        # Must have region_id to be useful
        region_id_str = entry.fields.get("region_id")
        if region_id_str is None:
            continue

        try:
            region_id = int(region_id_str)
        except ValueError:
            continue

        changes.append(LeadershipChange(
            timestamp=entry.timestamp,
            region_id=region_id,
            message=entry.message
        ))

    return changes
```

Export LogEntry, LeadershipChange, parse_log_line, extract_leadership_changes from package.
  </implementation>
</feature>

<verification>
TDD cycle verification:
1. RED: Tests written and failing (no implementation)
2. GREEN: Minimal implementation makes tests pass
3. REFACTOR: Clean up if needed, tests still pass

Final verification:
```bash
cd /Users/jrtipton/x/operator
uv run pytest packages/operator-tikv/tests/test_log_parser.py -v
```
</verification>

<success_criteria>
- All test cases pass
- Log parser handles TiDB unified log format correctly
- Leadership changes are extracted with region_id
- Malformed lines return None (don't crash)
- Functions exported from package __init__.py
</success_criteria>

<output>
After completion, create `.planning/phases/02-tikv-subject/02-04-SUMMARY.md`
</output>
