---
phase: 35-runner-layer
plan: 03
type: execute
wave: 2
depends_on: ["35-01", "35-02"]
files_modified:
  - eval/src/eval/runner/__init__.py
  - eval/src/eval/runner/db.py
  - eval/src/eval/runner/harness.py
autonomous: true

must_haves:
  truths:
    - "EvalDB persists campaigns and trials to eval.db"
    - "run_trial executes reset -> inject -> wait -> record sequence"
    - "Trial records include all timing fields (RUN-02)"
    - "Baseline trials skip agent waiting (RUN-05)"
  artifacts:
    - path: "eval/src/eval/runner/db.py"
      provides: "Async SQLite persistence"
      contains: "async def insert_trial"
    - path: "eval/src/eval/runner/harness.py"
      provides: "Campaign/trial runner"
      contains: "async def run_trial"
  key_links:
    - from: "eval/src/eval/runner/harness.py"
      to: "eval/src/eval/runner/db.py"
      via: "EvalDB usage"
      pattern: "EvalDB"
    - from: "eval/src/eval/runner/harness.py"
      to: "eval.types.EvalSubject"
      via: "protocol parameter"
      pattern: "subject: EvalSubject"
    - from: "eval/src/eval/runner/db.py"
      to: "aiosqlite"
      via: "async with aiosqlite.connect"
      pattern: "aiosqlite.connect"
---

<objective>
Implement eval database layer and campaign runner harness.

Purpose: Create the core execution engine that runs trials against eval subjects, captures timing data, and persists results to eval.db separate from operator.db.

Output: EvalDB class for persistence and run_trial/run_campaign functions for execution.
</objective>

<execution_context>
@/Users/jrtipton/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jrtipton/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/35-runner-layer/35-RESEARCH.md

# Reference for existing SQLite patterns
@packages/operator-core/src/operator_core/db/schema.py
@packages/operator-core/src/operator_core/db/audit_log.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create eval database layer</name>
  <files>
    eval/src/eval/runner/__init__.py
    eval/src/eval/runner/db.py
  </files>
  <action>
Create the database layer for eval persistence (RUN-06):

1. Create `eval/src/eval/runner/__init__.py`:
```python
"""Evaluation runner components."""

from eval.runner.db import EvalDB
from eval.runner.harness import run_trial, run_campaign

__all__ = ["EvalDB", "run_trial", "run_campaign"]
```

2. Create `eval/src/eval/runner/db.py`:
```python
"""Async SQLite persistence for evaluation data."""

import aiosqlite
from pathlib import Path

from eval.types import Campaign, Trial


SCHEMA_SQL = """
-- Campaign table
CREATE TABLE IF NOT EXISTS campaigns (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    subject_name TEXT NOT NULL,
    chaos_type TEXT NOT NULL,
    trial_count INTEGER NOT NULL,
    baseline INTEGER NOT NULL DEFAULT 0,
    created_at TEXT NOT NULL
);

-- Trial table with timing fields (RUN-02)
CREATE TABLE IF NOT EXISTS trials (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    campaign_id INTEGER NOT NULL,
    started_at TEXT NOT NULL,
    chaos_injected_at TEXT NOT NULL,
    ticket_created_at TEXT,
    resolved_at TEXT,
    ended_at TEXT NOT NULL,
    initial_state TEXT NOT NULL,
    final_state TEXT NOT NULL,
    chaos_metadata TEXT NOT NULL,
    commands_json TEXT NOT NULL DEFAULT '[]',
    FOREIGN KEY (campaign_id) REFERENCES campaigns(id)
);

-- Indexes
CREATE INDEX IF NOT EXISTS idx_trials_campaign ON trials(campaign_id);
"""


class EvalDB:
    """Async database for evaluation persistence.

    Uses aiosqlite for non-blocking database operations.
    IMPORTANT: Always call await db.commit() explicitly (see RESEARCH.md pitfall #3).
    """

    def __init__(self, db_path: Path):
        """Initialize with database path.

        Args:
            db_path: Path to eval.db file
        """
        self.db_path = db_path

    async def ensure_schema(self) -> None:
        """Create tables if not exist."""
        async with aiosqlite.connect(self.db_path) as db:
            await db.executescript(SCHEMA_SQL)
            await db.commit()

    async def insert_campaign(self, campaign: Campaign) -> int:
        """Insert campaign record, return campaign_id."""
        async with aiosqlite.connect(self.db_path) as db:
            cursor = await db.execute(
                """
                INSERT INTO campaigns (subject_name, chaos_type, trial_count, baseline, created_at)
                VALUES (?, ?, ?, ?, ?)
                """,
                (
                    campaign.subject_name,
                    campaign.chaos_type,
                    campaign.trial_count,
                    1 if campaign.baseline else 0,
                    campaign.created_at,
                ),
            )
            await db.commit()
            return cursor.lastrowid or 0

    async def insert_trial(self, trial: Trial) -> int:
        """Insert trial record, return trial_id."""
        async with aiosqlite.connect(self.db_path) as db:
            cursor = await db.execute(
                """
                INSERT INTO trials (
                    campaign_id, started_at, chaos_injected_at,
                    ticket_created_at, resolved_at, ended_at,
                    initial_state, final_state, chaos_metadata, commands_json
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """,
                (
                    trial.campaign_id,
                    trial.started_at,
                    trial.chaos_injected_at,
                    trial.ticket_created_at,
                    trial.resolved_at,
                    trial.ended_at,
                    trial.initial_state,
                    trial.final_state,
                    trial.chaos_metadata,
                    trial.commands_json,
                ),
            )
            await db.commit()
            return cursor.lastrowid or 0

    async def get_campaign(self, campaign_id: int) -> Campaign | None:
        """Get campaign by ID."""
        async with aiosqlite.connect(self.db_path) as db:
            db.row_factory = aiosqlite.Row
            cursor = await db.execute(
                "SELECT * FROM campaigns WHERE id = ?", (campaign_id,)
            )
            row = await cursor.fetchone()
            if row:
                return Campaign(
                    id=row["id"],
                    subject_name=row["subject_name"],
                    chaos_type=row["chaos_type"],
                    trial_count=row["trial_count"],
                    baseline=bool(row["baseline"]),
                    created_at=row["created_at"],
                )
            return None

    async def get_trials(self, campaign_id: int) -> list[Trial]:
        """Get all trials for a campaign."""
        async with aiosqlite.connect(self.db_path) as db:
            db.row_factory = aiosqlite.Row
            cursor = await db.execute(
                "SELECT * FROM trials WHERE campaign_id = ? ORDER BY id",
                (campaign_id,),
            )
            rows = await cursor.fetchall()
            return [
                Trial(
                    id=row["id"],
                    campaign_id=row["campaign_id"],
                    started_at=row["started_at"],
                    chaos_injected_at=row["chaos_injected_at"],
                    ticket_created_at=row["ticket_created_at"],
                    resolved_at=row["resolved_at"],
                    ended_at=row["ended_at"],
                    initial_state=row["initial_state"],
                    final_state=row["final_state"],
                    chaos_metadata=row["chaos_metadata"],
                    commands_json=row["commands_json"],
                )
                for row in rows
            ]
```

CRITICAL per RESEARCH.md:
- Always `await db.commit()` explicitly after INSERT/UPDATE
- aiosqlite context managers do NOT auto-commit
  </action>
  <verify>
Run: `cd eval && uv run python -c "
import asyncio
from pathlib import Path
from eval.runner.db import EvalDB
from eval.types import Campaign

async def test():
    db = EvalDB(Path('/tmp/test_eval.db'))
    await db.ensure_schema()
    c = Campaign(subject_name='test', chaos_type='node_kill', trial_count=1)
    cid = await db.insert_campaign(c)
    print(f'Campaign ID: {cid}')
    loaded = await db.get_campaign(cid)
    print(f'Loaded: {loaded}')

asyncio.run(test())
"`
Should print campaign ID and loaded campaign data.
  </verify>
  <done>EvalDB class persists campaigns and trials to SQLite with explicit commits</done>
</task>

<task type="auto">
  <name>Task 2: Implement trial runner harness</name>
  <files>
    eval/src/eval/runner/harness.py
  </files>
  <action>
Create the campaign/trial runner harness (RUN-01, RUN-02, RUN-03, RUN-04, RUN-05):

```python
"""Campaign and trial runner harness."""

import asyncio
import json
import sqlite3
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

from rich.console import Console

from eval.types import Campaign, EvalSubject, Trial
from eval.runner.db import EvalDB


console = Console()


def now() -> str:
    """Return current UTC timestamp in ISO8601 format."""
    return datetime.now(timezone.utc).isoformat()


async def extract_commands_from_operator_db(
    operator_db_path: Path,
    started_after: str,
) -> list[dict[str, Any]]:
    """Extract agent commands from operator.db after a timestamp.

    This implements RUN-04: Commands extracted from agent session for post-hoc analysis.

    Args:
        operator_db_path: Path to operator.db
        started_after: ISO8601 timestamp to filter entries

    Returns:
        List of command dicts with tool_name, tool_params, exit_code
    """
    if not operator_db_path.exists():
        return []

    # Use sync sqlite3 in thread pool (operator.db is sync)
    def query_commands():
        conn = sqlite3.connect(operator_db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.execute(
            """
            SELECT tool_name, tool_params, exit_code, timestamp
            FROM agent_log_entries
            WHERE entry_type = 'tool_call'
              AND timestamp > ?
            ORDER BY timestamp
            """,
            (started_after,),
        )
        rows = cursor.fetchall()
        conn.close()
        return [
            {
                "tool_name": row["tool_name"],
                "tool_params": row["tool_params"],
                "exit_code": row["exit_code"],
                "timestamp": row["timestamp"],
            }
            for row in rows
        ]

    return await asyncio.to_thread(query_commands)


async def wait_for_ticket_resolution(
    operator_db_path: Path,
    timeout_sec: float = 300.0,
) -> tuple[str | None, str | None]:
    """Wait for ticket to be created and resolved in operator.db.

    Args:
        operator_db_path: Path to operator.db
        timeout_sec: Maximum time to wait

    Returns:
        Tuple of (ticket_created_at, resolved_at) or (None, None) if timeout
    """
    if not operator_db_path.exists():
        return None, None

    start = asyncio.get_running_loop().time()

    while (asyncio.get_running_loop().time() - start) < timeout_sec:
        def query_ticket():
            conn = sqlite3.connect(operator_db_path)
            conn.row_factory = sqlite3.Row
            # Get most recent open or resolved ticket
            cursor = conn.execute(
                """
                SELECT first_seen_at, resolved_at, status
                FROM tickets
                ORDER BY id DESC
                LIMIT 1
                """
            )
            row = cursor.fetchone()
            conn.close()
            if row:
                return row["first_seen_at"], row["resolved_at"], row["status"]
            return None, None, None

        created, resolved, status = await asyncio.to_thread(query_ticket)

        if created:
            # Ticket exists
            if status == "resolved" and resolved:
                return created, resolved
            # Ticket not yet resolved, keep waiting

        await asyncio.sleep(2.0)

    # Timeout - return what we have
    return None, None


async def run_trial(
    subject: EvalSubject,
    chaos_type: str,
    campaign_id: int,
    baseline: bool = False,
    operator_db_path: Path | None = None,
) -> Trial:
    """Execute single trial with precise timing capture.

    Implements RUN-01 sequence: reset -> inject -> wait -> record

    Args:
        subject: EvalSubject to test
        chaos_type: Chaos type to inject
        campaign_id: Parent campaign ID
        baseline: If True, skip agent wait (RUN-05)
        operator_db_path: Path to operator.db for command extraction

    Returns:
        Completed Trial record
    """
    started_at = now()

    # Reset subject to clean state
    console.print("[bold blue]Resetting subject...[/bold blue]")
    await subject.reset()

    # Wait for healthy state
    console.print("[bold blue]Waiting for healthy state...[/bold blue]")
    healthy = await subject.wait_healthy(timeout_sec=120.0)
    if not healthy:
        console.print("[bold red]Subject failed to become healthy[/bold red]")

    # Capture initial state (RUN-03)
    console.print("[bold blue]Capturing initial state...[/bold blue]")
    initial_state = await subject.capture_state()

    # Inject chaos
    console.print(f"[bold yellow]Injecting chaos: {chaos_type}[/bold yellow]")
    chaos_injected_at = now()
    chaos_metadata = await subject.inject_chaos(chaos_type)
    console.print(f"[dim]Chaos metadata: {chaos_metadata}[/dim]")

    # Wait for resolution (unless baseline)
    ticket_created_at = None
    resolved_at = None
    commands: list[dict[str, Any]] = []

    if baseline:
        # RUN-05: Baseline trials run without agent
        console.print("[bold cyan]Baseline mode: waiting for self-healing...[/bold cyan]")
        # Just wait for subject to recover on its own
        await subject.wait_healthy(timeout_sec=300.0)
    else:
        # Normal trial: wait for agent to resolve
        console.print("[bold cyan]Waiting for agent resolution...[/bold cyan]")
        if operator_db_path:
            ticket_created_at, resolved_at = await wait_for_ticket_resolution(
                operator_db_path, timeout_sec=300.0
            )

            # Extract commands (RUN-04)
            if ticket_created_at:
                commands = await extract_commands_from_operator_db(
                    operator_db_path, started_at
                )
                console.print(f"[dim]Extracted {len(commands)} commands[/dim]")

    # Capture final state (RUN-03)
    console.print("[bold blue]Capturing final state...[/bold blue]")
    final_state = await subject.capture_state()

    ended_at = now()

    return Trial(
        campaign_id=campaign_id,
        started_at=started_at,
        chaos_injected_at=chaos_injected_at,
        ticket_created_at=ticket_created_at,
        resolved_at=resolved_at,
        ended_at=ended_at,
        initial_state=json.dumps(initial_state),
        final_state=json.dumps(final_state),
        chaos_metadata=json.dumps(chaos_metadata),
        commands_json=json.dumps(commands),
    )


async def run_campaign(
    subject: EvalSubject,
    subject_name: str,
    chaos_type: str,
    trial_count: int,
    db: EvalDB,
    baseline: bool = False,
    operator_db_path: Path | None = None,
) -> int:
    """Run campaign of N trials sequentially.

    Args:
        subject: EvalSubject to test
        subject_name: Name for reporting (e.g., "TiKVEvalSubject")
        chaos_type: Chaos type to inject
        trial_count: Number of trials
        db: EvalDB for persistence
        baseline: If True, skip agent wait
        operator_db_path: Path to operator.db for command extraction

    Returns:
        campaign_id for later analysis
    """
    # Create campaign record
    campaign = Campaign(
        subject_name=subject_name,
        chaos_type=chaos_type,
        trial_count=trial_count,
        baseline=baseline,
        created_at=now(),
    )
    campaign_id = await db.insert_campaign(campaign)
    console.print(f"[bold green]Campaign {campaign_id} started[/bold green]")

    # Run trials sequentially (avoid SQLite write contention - RESEARCH.md pitfall #1)
    for trial_num in range(trial_count):
        console.print(f"\n[bold]Trial {trial_num + 1}/{trial_count}[/bold]")

        trial = await run_trial(
            subject=subject,
            chaos_type=chaos_type,
            campaign_id=campaign_id,
            baseline=baseline,
            operator_db_path=operator_db_path,
        )

        trial_id = await db.insert_trial(trial)
        console.print(f"[green]Trial {trial_id} completed at {trial.ended_at}[/green]")

    console.print(f"\n[bold green]Campaign {campaign_id} complete[/bold green]")
    return campaign_id
```

Key implementation notes:
- Sequential trial execution per RESEARCH.md pitfall #1
- All timestamps use `datetime.now(timezone.utc).isoformat()`
- Baseline mode skips agent polling (RUN-05)
- Command extraction queries operator.db post-hoc (RUN-04)
  </action>
  <verify>
Run: `cd eval && uv run python -c "from eval.runner import run_trial, run_campaign, EvalDB; print('Harness imports OK')"`
  </verify>
  <done>run_trial and run_campaign functions implement reset->inject->wait->record sequence with all timing fields</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. `ls -la eval/src/eval/runner/` shows __init__.py, db.py, harness.py
2. `uv run python -c "from eval.runner import EvalDB, run_trial, run_campaign"` succeeds
3. `grep "await db.commit" eval/src/eval/runner/db.py | wc -l` shows commits in each method
4. `grep "baseline" eval/src/eval/runner/harness.py | wc -l` shows baseline handling
</verification>

<success_criteria>
- [ ] eval/src/eval/runner/ directory exists with db.py and harness.py
- [ ] EvalDB.ensure_schema() creates campaigns and trials tables
- [ ] EvalDB.insert_campaign/insert_trial include explicit await db.commit()
- [ ] run_trial() captures started_at, chaos_injected_at, ticket_created_at, resolved_at, ended_at
- [ ] run_trial() captures initial_state and final_state via subject.capture_state()
- [ ] run_trial() with baseline=True skips agent waiting
- [ ] run_trial() extracts commands from operator.db when operator_db_path provided
- [ ] run_campaign() executes trials sequentially (not parallel)
</success_criteria>

<output>
After completion, create `.planning/phases/35-runner-layer/35-03-SUMMARY.md`
</output>
