---
phase: 35-runner-layer
plan: 04
type: execute
wave: 3
depends_on: ["35-01", "35-02", "35-03"]
files_modified:
  - eval/src/eval/cli.py
  - eval/src/eval/__init__.py
autonomous: false

must_haves:
  truths:
    - "Developer can run `eval run --subject tikv --chaos node_kill` and trial executes"
    - "Developer can run `eval run --baseline` and trial executes without agent"
    - "Trial data persists in eval.db with timing data"
  artifacts:
    - path: "eval/src/eval/cli.py"
      provides: "eval CLI with run command"
      contains: "@run_app.command"
    - path: "eval/pyproject.toml"
      provides: "CLI script entry"
      contains: 'eval = "eval.cli:main"'
  key_links:
    - from: "eval/src/eval/cli.py"
      to: "eval.runner.harness"
      via: "asyncio.run(run_trial)"
      pattern: "asyncio.run"
    - from: "eval/src/eval/cli.py"
      to: "eval.subjects.tikv.TiKVEvalSubject"
      via: "subject loading"
      pattern: "TiKVEvalSubject"
---

<objective>
Implement the eval CLI with run command for single-trial execution.

Purpose: Provide the developer interface for running evaluations. This is the entry point that ties together the subject, harness, and database components.

Output: `eval` CLI command that can execute `eval run --subject tikv --chaos node_kill` and `eval run --baseline`.
</objective>

<execution_context>
@/Users/jrtipton/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jrtipton/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/35-runner-layer/35-RESEARCH.md

# Reference for existing CLI patterns
@packages/operator-core/src/operator_core/cli/main.py
@packages/operator-core/src/operator_core/cli/agent.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement eval CLI</name>
  <files>
    eval/src/eval/cli.py
  </files>
  <action>
Create CLI with run command (CLI-01, CLI-02):

```python
"""Evaluation harness CLI."""

import asyncio
from pathlib import Path
from typing import Optional

import typer
from rich.console import Console
from rich.table import Table

from eval.runner.db import EvalDB
from eval.runner.harness import run_trial, run_campaign
from eval.subjects.tikv import TiKVEvalSubject
from eval.types import EvalSubject

app = typer.Typer(
    name="eval",
    help="Evaluation harness for chaos engineering trials",
    no_args_is_help=True,
)

run_app = typer.Typer(help="Run evaluation trials")
app.add_typer(run_app, name="run")

console = Console()


def get_subject(subject_name: str) -> EvalSubject:
    """Load eval subject by name.

    Args:
        subject_name: Subject identifier (e.g., 'tikv')

    Returns:
        EvalSubject implementation

    Raises:
        typer.BadParameter: If subject not found
    """
    if subject_name.lower() == "tikv":
        return TiKVEvalSubject()

    raise typer.BadParameter(f"Unknown subject: {subject_name}. Available: tikv")


@run_app.callback(invoke_without_command=True)
def run_single(
    ctx: typer.Context,
    subject: str = typer.Option(
        "tikv",
        "--subject", "-s",
        help="Subject to test (e.g., 'tikv')",
    ),
    chaos: str = typer.Option(
        "node_kill",
        "--chaos", "-c",
        help="Chaos type to inject (e.g., 'node_kill')",
    ),
    baseline: bool = typer.Option(
        False,
        "--baseline", "-b",
        help="Run without agent (self-healing test)",
    ),
    db_path: Path = typer.Option(
        Path("eval.db"),
        "--db",
        help="Path to eval database",
    ),
    operator_db: Optional[Path] = typer.Option(
        None,
        "--operator-db",
        help="Path to operator.db for command extraction",
    ),
    trials: int = typer.Option(
        1,
        "--trials", "-n",
        help="Number of trials to run",
    ),
) -> None:
    """Run evaluation trial(s) against a subject.

    Examples:
        eval run --subject tikv --chaos node_kill
        eval run --baseline
        eval run --trials 5
    """
    # If subcommand was invoked, skip
    if ctx.invoked_subcommand is not None:
        return

    # Validate chaos type
    eval_subject = get_subject(subject)
    available_chaos = eval_subject.get_chaos_types()

    if chaos not in available_chaos:
        raise typer.BadParameter(
            f"Unknown chaos type: {chaos}. Available for {subject}: {available_chaos}"
        )

    # Auto-detect operator.db if not specified
    if operator_db is None and not baseline:
        default_operator_db = Path("data/operator.db")
        if default_operator_db.exists():
            operator_db = default_operator_db
            console.print(f"[dim]Using operator.db: {operator_db}[/dim]")

    # Run evaluation
    async def run():
        db = EvalDB(db_path)
        await db.ensure_schema()

        if trials == 1:
            # Single trial (CLI-01, CLI-02)
            console.print(f"\n[bold]Running single trial[/bold]")
            console.print(f"Subject: {subject}")
            console.print(f"Chaos: {chaos}")
            console.print(f"Baseline: {baseline}")
            console.print(f"Database: {db_path}\n")

            # Create a single-trial campaign
            from eval.types import Campaign
            from eval.runner.harness import now

            campaign = Campaign(
                subject_name=subject,
                chaos_type=chaos,
                trial_count=1,
                baseline=baseline,
                created_at=now(),
            )
            campaign_id = await db.insert_campaign(campaign)

            trial = await run_trial(
                subject=eval_subject,
                chaos_type=chaos,
                campaign_id=campaign_id,
                baseline=baseline,
                operator_db_path=operator_db,
            )

            trial_id = await db.insert_trial(trial)

            # Print summary
            console.print(f"\n[bold green]Trial complete![/bold green]")
            console.print(f"Campaign ID: {campaign_id}")
            console.print(f"Trial ID: {trial_id}")
            console.print(f"Started: {trial.started_at}")
            console.print(f"Chaos injected: {trial.chaos_injected_at}")
            if trial.ticket_created_at:
                console.print(f"Ticket created: {trial.ticket_created_at}")
            if trial.resolved_at:
                console.print(f"Resolved: {trial.resolved_at}")
            console.print(f"Ended: {trial.ended_at}")

        else:
            # Multiple trials (campaign)
            campaign_id = await run_campaign(
                subject=eval_subject,
                subject_name=subject,
                chaos_type=chaos,
                trial_count=trials,
                db=db,
                baseline=baseline,
                operator_db_path=operator_db,
            )

            console.print(f"\n[bold green]Campaign {campaign_id} complete with {trials} trials[/bold green]")

    asyncio.run(run())


def main() -> None:
    """Entry point for the CLI."""
    app()


if __name__ == "__main__":
    main()
```

Key patterns:
- Uses asyncio.run() to bridge sync CLI to async harness (RESEARCH.md pattern #5)
- Auto-detects operator.db if not specified
- Validates chaos type against subject's available types
- Single trial creates a 1-trial campaign for consistency
  </action>
  <verify>
Run: `cd eval && uv pip install -e . && eval --help`
Should show "run" subcommand.
Run: `eval run --help`
Should show --subject, --chaos, --baseline, --db options.
  </verify>
  <done>eval CLI installs and shows run command with --subject, --chaos, --baseline options</done>
</task>

<task type="auto">
  <name>Task 2: Update package exports</name>
  <files>
    eval/src/eval/__init__.py
  </files>
  <action>
Update __init__.py to export runner components:

```python
"""Evaluation harness for chaos engineering trials."""

from eval.types import (
    EvalSubject,
    ChaosType,
    Campaign,
    Trial,
)
from eval.runner.db import EvalDB
from eval.runner.harness import run_trial, run_campaign

__version__ = "0.1.0"

__all__ = [
    # Types
    "EvalSubject",
    "ChaosType",
    "Campaign",
    "Trial",
    # Runner
    "EvalDB",
    "run_trial",
    "run_campaign",
]
```
  </action>
  <verify>
Run: `cd eval && uv run python -c "from eval import EvalDB, run_trial, run_campaign; print('All exports OK')"`
  </verify>
  <done>eval package exports EvalDB, run_trial, run_campaign from top-level</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete eval harness with CLI for running trials against TiKV subject</what-built>
  <how-to-verify>
1. Start TiKV cluster:
   ```bash
   cd subjects/tikv && docker compose up -d
   ```

2. Wait for healthy state:
   ```bash
   docker compose ps  # All containers should be healthy
   ```

3. Run single trial (without operator running - just tests harness):
   ```bash
   cd /Users/jrtipton/x/operator
   eval run --subject tikv --chaos node_kill --baseline
   ```

4. Verify output shows:
   - "Resetting subject..."
   - "Waiting for healthy state..."
   - "Capturing initial state..."
   - "Injecting chaos: node_kill"
   - "Baseline mode: waiting for self-healing..."
   - "Trial complete!" with timing data

5. Verify database:
   ```bash
   sqlite3 eval.db "SELECT * FROM campaigns; SELECT * FROM trials;"
   ```
   Should show campaign and trial records with timing fields.

6. Clean up:
   ```bash
   cd subjects/tikv && docker compose down -v
   ```
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues</resume-signal>
</task>

</tasks>

<verification>
After all tasks complete:
1. `eval --help` shows run command
2. `eval run --help` shows --subject, --chaos, --baseline, --trials options
3. `eval run --baseline` completes and creates records in eval.db
4. sqlite3 eval.db shows campaigns and trials tables with data
</verification>

<success_criteria>
- [ ] eval CLI installs via pyproject.toml scripts entry
- [ ] `eval run --subject tikv --chaos node_kill` runs single trial
- [ ] `eval run --baseline` runs trial without agent waiting
- [ ] Trial data persists to eval.db with all timing fields
- [ ] CLI validates chaos type against subject's available types
- [ ] Human verification confirms end-to-end flow works
</success_criteria>

<output>
After completion, create `.planning/phases/35-runner-layer/35-04-SUMMARY.md`
</output>
