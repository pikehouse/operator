---
phase: 01-foundation
plan: 03
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - packages/operator-core/src/operator_core/deploy.py
autonomous: true

must_haves:
  truths:
    - "DeploymentTarget Protocol defines up/down/status/logs/restart operations"
    - "LocalDeployment implementation uses python-on-whales"
    - "Deployment abstraction allows swapping local for cloud without changing operator code"
  artifacts:
    - path: "packages/operator-core/src/operator_core/deploy.py"
      provides: "Deployment abstraction and local implementation"
      contains: "class DeploymentTarget"
  key_links:
    - from: "packages/operator-core/src/operator_core/deploy.py"
      to: "python_on_whales"
      via: "DockerClient import"
      pattern: "from python_on_whales import"
---

<objective>
Create the deployment abstraction (DEPLOY-01) with the local Docker Compose implementation (DEPLOY-02).

Purpose: Clean separation between deployment logic and deployment targets. The same operator code can deploy to local Docker Compose or (later) cloud providers by swapping the deployment implementation.

Output: DeploymentTarget Protocol and LocalDeployment class using python-on-whales for Docker Compose control.
</objective>

<execution_context>
@/Users/jrtipton/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jrtipton/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/01-foundation/01-CONTEXT.md
@.planning/phases/01-foundation/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create DeploymentTarget Protocol</name>
  <files>packages/operator-core/src/operator_core/deploy.py</files>
  <action>
Create the deployment module with Protocol and implementation:

1. Define DeploymentTarget Protocol (NOT runtime_checkable - static typing only):

```python
from typing import Protocol
from pathlib import Path
from dataclasses import dataclass

@dataclass
class ServiceStatus:
    name: str
    running: bool
    health: str  # "healthy", "unhealthy", "starting", "none"
    ports: list[str]  # "host:container" format

@dataclass
class DeploymentStatus:
    services: list[ServiceStatus]
    all_healthy: bool

class DeploymentTarget(Protocol):
    """Interface for deployment targets (local, AWS, etc.)"""

    def up(self, wait: bool = True) -> None:
        """Start the deployment. If wait=True, block until healthy."""
        ...

    def down(self, remove_volumes: bool = False) -> None:
        """Stop the deployment."""
        ...

    def status(self) -> DeploymentStatus:
        """Get status of all services."""
        ...

    def logs(self, service: str | None = None, follow: bool = False, tail: int = 100) -> None:
        """Show logs. If service=None, show all. If follow=True, stream."""
        ...

    def restart(self, service: str) -> None:
        """Restart a specific service."""
        ...
```

2. Create LocalDeployment implementation:

```python
from python_on_whales import DockerClient
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn

class LocalDeployment:
    """Docker Compose-based local deployment."""

    def __init__(self, compose_file: Path, project_name: str | None = None):
        self.compose_file = compose_file
        self.docker = DockerClient(compose_files=[compose_file])
        self.console = Console()
        self.project_name = project_name

    def up(self, wait: bool = True) -> None:
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=self.console,
        ) as progress:
            task = progress.add_task("Starting containers...", total=None)
            self.docker.compose.up(detach=True, wait=wait)
            progress.update(task, description="[green]Cluster ready!")

        # Print service endpoints after startup
        self._print_endpoints()

    def down(self, remove_volumes: bool = False) -> None:
        self.docker.compose.down(volumes=remove_volumes)
        self.console.print("[yellow]Cluster stopped[/yellow]")

    def status(self) -> DeploymentStatus:
        containers = self.docker.compose.ps()
        services = []
        for c in containers:
            # Get health status if available
            health = "none"
            if hasattr(c, 'state') and hasattr(c.state, 'health'):
                health = c.state.health.status if c.state.health else "none"

            # Get port mappings
            ports = []
            if c.network_settings and c.network_settings.ports:
                for container_port, host_bindings in c.network_settings.ports.items():
                    if host_bindings:
                        for binding in host_bindings:
                            ports.append(f"{binding.host_port}:{container_port}")

            services.append(ServiceStatus(
                name=c.name,
                running=c.state.running if hasattr(c, 'state') else False,
                health=health,
                ports=ports,
            ))

        all_healthy = all(s.running for s in services)
        return DeploymentStatus(services=services, all_healthy=all_healthy)

    def logs(self, service: str | None = None, follow: bool = False, tail: int = 100) -> None:
        if service:
            self.docker.compose.logs(services=[service], follow=follow, tail=str(tail))
        else:
            self.docker.compose.logs(follow=follow, tail=str(tail))

    def restart(self, service: str) -> None:
        self.docker.compose.restart(services=[service])
        self.console.print(f"[green]Restarted {service}[/green]")

    def _print_endpoints(self) -> None:
        """Print service endpoints after successful startup."""
        self.console.print("\n[bold]Services:[/bold]")
        status = self.status()
        for svc in status.services:
            if svc.ports:
                for port in svc.ports:
                    host_port = port.split(":")[0]
                    self.console.print(f"  {svc.name}: http://localhost:{host_port}")
```

3. Add factory function for creating deployments:

```python
def create_local_deployment(subject: str, base_path: Path | None = None) -> LocalDeployment:
    """Create a LocalDeployment for a subject.

    Args:
        subject: Subject name (e.g., "tikv")
        base_path: Project root path. If None, uses current directory.

    Returns:
        LocalDeployment configured for the subject's compose file.
    """
    if base_path is None:
        base_path = Path.cwd()

    compose_file = base_path / "subjects" / subject / "docker-compose.yaml"
    if not compose_file.exists():
        raise FileNotFoundError(f"Compose file not found: {compose_file}")

    return LocalDeployment(compose_file, project_name=f"operator-{subject}")
```

4. Update __init__.py to export deployment types.
  </action>
  <verify>
Run:
```bash
uv run python -c "
from operator_core.deploy import DeploymentTarget, LocalDeployment, ServiceStatus, DeploymentStatus
from pathlib import Path
# Just verify imports work - don't try to deploy without compose file
print('DeploymentTarget:', DeploymentTarget)
print('LocalDeployment:', LocalDeployment)
"
```
Type check: `uv run python -m py_compile packages/operator-core/src/operator_core/deploy.py`
  </verify>
  <done>
- DeploymentTarget Protocol defined with up/down/status/logs/restart
- LocalDeployment implementation uses python-on-whales
- ServiceStatus and DeploymentStatus types provide structured status info
- Factory function creates LocalDeployment from subject name
  </done>
</task>

<task type="auto">
  <name>Task 2: Update package exports</name>
  <files>packages/operator-core/src/operator_core/__init__.py</files>
  <action>
Update the package __init__.py to export all public types:

```python
"""Operator Core - AI-powered operator for distributed systems."""

__version__ = "0.1.0"

# Re-export public types for convenient imports
from operator_core.deploy import (
    DeploymentTarget,
    LocalDeployment,
    ServiceStatus,
    DeploymentStatus,
    create_local_deployment,
)

__all__ = [
    "__version__",
    "DeploymentTarget",
    "LocalDeployment",
    "ServiceStatus",
    "DeploymentStatus",
    "create_local_deployment",
]
```

Note: Subject types will be added in Plan 02. This plan focuses on deployment.
  </action>
  <verify>
```bash
uv run python -c "from operator_core import LocalDeployment, DeploymentTarget; print('OK')"
```
  </verify>
  <done>
- Package exports deployment types
- Users can import directly from operator_core
  </done>
</task>

</tasks>

<verification>
1. All deployment types import from operator_core:
   ```bash
   uv run python -c "from operator_core import LocalDeployment, DeploymentTarget, create_local_deployment"
   ```
2. LocalDeployment can be instantiated (though won't work without actual compose file):
   ```bash
   uv run python -c "
   from operator_core.deploy import LocalDeployment
   from pathlib import Path
   # This will fail on missing file, but proves the class works
   try:
       ld = LocalDeployment(Path('/nonexistent/docker-compose.yaml'))
   except Exception as e:
       print(f'Expected error (no compose file): {type(e).__name__}')
   "
   ```
3. Type checking passes
</verification>

<success_criteria>
- DEPLOY-01 requirement satisfied: DeploymentTarget Protocol exists
- DEPLOY-02 partially satisfied: LocalDeployment implementation exists (CLI comes in Plan 04)
- Abstraction allows swapping implementations via the Protocol
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-03-SUMMARY.md`
</output>
