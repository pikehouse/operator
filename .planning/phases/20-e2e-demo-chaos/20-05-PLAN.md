---
phase: 20-e2e-demo-chaos
plan: 05
type: execute
wave: 4
depends_on: ["20-04"]
files_modified: []
autonomous: false

must_haves:
  truths:
    - "Rate limiter demo runs and shows counter drift anomaly"
    - "Rate limiter demo runs and shows ghost allowing anomaly"
    - "AI diagnosis identifies anomaly types without system-specific prompts"
    - "TiKV demo still works after refactoring"
  artifacts: []
  key_links: []
---

<objective>
Validate E2E demo for both subjects with AI diagnosis verification.

Purpose: Prove the core thesis of Phase 20 - AI can diagnose rate limiter anomalies without system-specific prompts in core reasoning, using the same patterns as TiKV.

Output: Verified working demos for both subjects with AI successfully identifying anomaly types.
</objective>

<execution_context>
@/Users/jrtipton/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jrtipton/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/20-e2e-demo-chaos/20-04-SUMMARY.md
</context>

<tasks>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Rate limiter E2E demo with counter drift and ghost allowing chaos scenarios</what-built>
  <how-to-verify>
1. Start rate limiter cluster:
   ```bash
   cd docker && docker compose up -d
   ```

2. Wait for all services healthy (check Prometheus at http://localhost:9090)

3. Run rate limiter demo:
   ```bash
   ./scripts/run-demo.sh ratelimiter
   ```
   Or: `python -m demo ratelimiter`

4. Progress through chapters:
   - Press SPACE/ENTER to advance
   - Observe cluster health in left panel
   - Watch for "Counter Drift Chaos" chapter (Redis PAUSE injection)
   - Monitor should detect counter_drift or redis_disconnected violation
   - Agent should diagnose the issue

5. Continue to ghost allowing chaos:
   - "Ghost Allowing Chaos" chapter sends burst traffic
   - Monitor should detect ghost_allowing violation
   - Agent should diagnose the issue

6. Verify AI diagnosis:
   - Counter drift: AI should mention Redis unavailability or counter inconsistency
   - Ghost allowing: AI should mention requests allowed beyond limit or limit=0

7. Demo should complete cleanly with Q or reaching final chapter

Expected behavior:
- Panels update in real-time
- Chaos injection causes visible violations
- AI generates meaningful diagnosis text
  </how-to-verify>
  <resume-signal>Type "approved" if demo works correctly for rate limiter, or describe issues</resume-signal>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>TiKV E2E demo still works after demo framework refactoring</what-built>
  <how-to-verify>
1. Start TiKV cluster:
   ```bash
   cd subjects/tikv && docker compose up -d
   ```

2. Wait for cluster healthy (check PD at http://localhost:2379/pd/api/v1/stores)

3. Run TiKV demo:
   ```bash
   ./scripts/run-demo.sh tikv
   ```
   Or: `python -m demo tikv`

4. Progress through chapters:
   - Welcome, Cluster Health, Load Generation
   - Fault Injection (kills TiKV node)
   - Detection (monitor finds store_down violation)
   - AI Diagnosis
   - Recovery (restarts node)

5. Verify:
   - Cluster panel shows node health with up/down indicators
   - Killed node shows as DOWN/Disconnected
   - AI diagnosis mentions node failure and affected store
   - Node recovery shown after restart

Expected: Same behavior as before refactoring, but using new demo framework.
  </how-to-verify>
  <resume-signal>Type "approved" if TiKV demo works correctly, or describe issues</resume-signal>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>AI diagnosis quality validation - no system-specific prompts needed</what-built>
  <how-to-verify>
1. Review AI diagnosis output from both demos

2. For rate limiter diagnosis, verify:
   - AI identified the anomaly type (counter drift OR ghost allowing)
   - AI mentioned the affected component (Redis, specific node, or key)
   - Diagnosis is actionable (suggests what to investigate or fix)
   - AI did NOT require rate-limiter-specific prompts in operator-core

3. For TiKV diagnosis, verify:
   - Still identifies store_down correctly
   - Mentions affected TiKV store/node

4. Compare reasoning quality:
   - Rate limiter diagnosis should be comparable quality to TiKV
   - Both should show structured reasoning (what happened, why, options)

5. Check that operator-core agent prompt is generic:
   - Review packages/operator-core/src/operator_core/agent/prompt.py
   - Confirm no rate-limiter-specific prompts
   - Subject-specific terminology comes from observation dict, not hardcoded

Success criteria from ROADMAP.md:
- AI correctly identifies root cause without rate-limiter-specific prompts in core
  </how-to-verify>
  <resume-signal>Type "approved" if AI diagnosis meets quality bar, or describe what's missing</resume-signal>
</task>

</tasks>

<verification>
1. Rate limiter demo runs without crashes
2. TiKV demo runs without crashes
3. Both demos show real-time panel updates
4. AI diagnosis is generated for violations
5. Diagnosis quality is acceptable for both subjects
</verification>

<success_criteria>
- Chaos injection causes counter drift anomaly (partition then observe)
- Chaos injection causes ghost allowing anomaly (boundary burst)
- AI correctly identifies root cause without rate-limiter-specific prompts in core
- Same demo patterns work for both TiKV and rate limiter subjects
</success_criteria>

<output>
After completion, create `.planning/phases/20-e2e-demo-chaos/20-05-SUMMARY.md`
</output>
