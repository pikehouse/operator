---
phase: 38-chaos-expansion
plan: 02
type: execute
wave: 2
depends_on: ["38-01"]
files_modified:
  - eval/pyproject.toml
  - eval/src/eval/runner/campaign.py
  - eval/src/eval/runner/harness.py
  - eval/src/eval/runner/db.py
  - eval/src/eval/cli.py
autonomous: true

must_haves:
  truths:
    - "Developer can define campaign configuration in YAML file"
    - "YAML config supports matrix expansion (subjects x chaos_types)"
    - "Developer can run eval run campaign config.yaml and see trials execute"
    - "Campaign runner respects parallel and cooldown_seconds settings"
    - "Campaign state persists to database for resumability"
    - "Failed trials are marked as failed but campaign continues"
  artifacts:
    - path: "eval/pyproject.toml"
      provides: "PyYAML dependency"
      contains: "pyyaml"
    - path: "eval/src/eval/runner/campaign.py"
      provides: "CampaignConfig Pydantic model and expand_matrix function"
      exports: ["CampaignConfig", "ChaosSpec", "expand_campaign_matrix", "load_campaign_config"]
    - path: "eval/src/eval/runner/harness.py"
      provides: "run_campaign_from_config function with parallel execution"
      contains: "Semaphore"
    - path: "eval/src/eval/runner/db.py"
      provides: "Campaign resumability tracking"
      contains: "status"
    - path: "eval/src/eval/cli.py"
      provides: "eval run campaign subcommand"
      contains: "campaign"
  key_links:
    - from: "eval/src/eval/cli.py"
      to: "eval/src/eval/runner/campaign.py"
      via: "load_campaign_config import"
      pattern: "load_campaign_config"
    - from: "eval/src/eval/runner/harness.py"
      to: "eval/src/eval/runner/campaign.py"
      via: "expand_campaign_matrix call"
      pattern: "expand_campaign_matrix"
    - from: "eval/src/eval/runner/harness.py"
      to: "eval/src/eval/subjects/tikv/subject.py"
      via: "cleanup_chaos call after trial"
      pattern: "cleanup_chaos"
---

<objective>
Implement YAML-based campaign configuration and batch trial execution with parallel support.

Purpose: Enable batch evaluation campaigns with matrix expansion across subjects and chaos types, supporting controlled parallelism and resumability.

Output: Campaign YAML loader, matrix expansion, parallel runner with semaphore control, CLI command for campaign execution.
</objective>

<execution_context>
@/Users/jrtipton/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jrtipton/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/38-chaos-expansion/38-CONTEXT.md
@.planning/phases/38-chaos-expansion/38-RESEARCH.md

# Existing implementation patterns
@eval/src/eval/runner/harness.py
@eval/src/eval/runner/db.py
@eval/src/eval/cli.py
@eval/src/eval/types.py
@eval/pyproject.toml

# Prior plan summary (chaos functions)
@.planning/phases/38-chaos-expansion/38-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add PyYAML dependency and create campaign config module</name>
  <files>
    eval/pyproject.toml
    eval/src/eval/runner/campaign.py
  </files>
  <action>
    1. Update eval/pyproject.toml:
       - Add "pyyaml>=6.0" to dependencies list

    2. Create eval/src/eval/runner/campaign.py with:

       ```python
       """Campaign YAML configuration loading and matrix expansion."""

       from itertools import product
       from pathlib import Path
       from typing import Any

       import yaml
       from pydantic import BaseModel, Field, field_validator


       class ChaosSpec(BaseModel):
           """Per-chaos-type configuration."""
           type: str  # "node_kill", "latency", "disk_pressure", "network_partition"
           params: dict[str, Any] = Field(default_factory=dict)

           @field_validator("type")
           @classmethod
           def validate_chaos_type(cls, v: str) -> str:
               valid_types = ["node_kill", "latency", "disk_pressure", "network_partition"]
               if v not in valid_types:
                   raise ValueError(f"Invalid chaos type: {v}. Must be one of {valid_types}")
               return v


       class CampaignConfig(BaseModel):
           """Campaign YAML schema with validation."""
           name: str
           subjects: list[str] = Field(default_factory=lambda: ["tikv"])
           chaos_types: list[ChaosSpec]
           trials_per_combination: int = Field(default=1, ge=1)
           parallel: int = Field(default=1, ge=1, le=10)
           cooldown_seconds: int = Field(default=0, ge=0)
           include_baseline: bool = False

           @field_validator("subjects")
           @classmethod
           def validate_subjects(cls, v: list[str]) -> list[str]:
               valid_subjects = ["tikv"]  # Extend as more subjects added
               for s in v:
                   if s not in valid_subjects:
                       raise ValueError(f"Invalid subject: {s}. Must be one of {valid_subjects}")
               return v


       def load_campaign_config(path: Path) -> CampaignConfig:
           """Load and validate campaign config from YAML file."""
           with open(path) as f:
               data = yaml.safe_load(f)
           return CampaignConfig.model_validate(data)


       def expand_campaign_matrix(config: CampaignConfig) -> list[dict[str, Any]]:
           """Generate trial specifications from matrix (subjects x chaos_types x trials_per_combination)."""
           trials = []

           # Cartesian product: subjects x chaos_types
           for subject, chaos in product(config.subjects, config.chaos_types):
               for trial_idx in range(config.trials_per_combination):
                   trials.append({
                       "subject": subject,
                       "chaos_type": chaos.type,
                       "chaos_params": chaos.params,
                       "trial_index": trial_idx,
                       "baseline": False,
                   })

           # Optional baseline trials (one per subject, no chaos)
           if config.include_baseline:
               for subject in config.subjects:
                   trials.append({
                       "subject": subject,
                       "chaos_type": "none",
                       "chaos_params": {},
                       "trial_index": 0,
                       "baseline": True,
                   })

           return trials
       ```
  </action>
  <verify>
    cd /Users/jrtipton/x/operator/eval && uv pip install pyyaml>=6.0 2>/dev/null || pip install pyyaml>=6.0
    python -c "from eval.runner.campaign import CampaignConfig, expand_campaign_matrix; print('imports ok')"
  </verify>
  <done>
    PyYAML added to dependencies; campaign.py provides CampaignConfig Pydantic model and matrix expansion
  </done>
</task>

<task type="auto">
  <name>Task 2: Update harness with parallel campaign runner</name>
  <files>
    eval/src/eval/runner/harness.py
  </files>
  <action>
    Add new function to harness.py for campaign-based execution with parallel support:

    1. Add imports at top:
       ```python
       from eval.runner.campaign import CampaignConfig, expand_campaign_matrix
       ```

    2. Update run_trial() to:
       - Accept optional chaos_params dict (for latency min_ms/max_ms, disk fill_percent, etc.)
       - Pass chaos_params to subject.inject_chaos(chaos_type, **chaos_params)
       - After capturing final_state, call subject.cleanup_chaos(chaos_metadata) in finally block
       - Handle cleanup errors gracefully (container may have been killed)

    3. Add run_campaign_from_config() function:
       ```python
       async def run_campaign_from_config(
           config: CampaignConfig,
           db: EvalDB,
           operator_db_path: Path | None = None,
       ) -> int:
           """Run campaign from YAML config with parallel execution.

           Uses asyncio.Semaphore to limit concurrent trials.
           Continues campaign even if individual trials fail.

           Args:
               config: Loaded CampaignConfig
               db: EvalDB for persistence
               operator_db_path: Path to operator.db for command extraction

           Returns:
               campaign_id for later analysis
           """
           from eval.subjects.tikv import TiKVEvalSubject

           # Expand matrix to trial specs
           trial_specs = expand_campaign_matrix(config)
           total_trials = len(trial_specs)

           # Create campaign record
           campaign = Campaign(
               subject_name=",".join(config.subjects),
               chaos_type=",".join(c.type for c in config.chaos_types),
               trial_count=total_trials,
               baseline=config.include_baseline,
               created_at=now(),
           )
           campaign_id = await db.insert_campaign(campaign)
           console.print(f"[bold green]Campaign {campaign_id} started ({total_trials} trials)[/bold green]")

           # Semaphore for parallelism control
           semaphore = asyncio.Semaphore(config.parallel)
           completed = 0
           failed = 0

           async def run_single_trial(spec: dict, trial_num: int) -> Trial | None:
               nonlocal completed, failed
               async with semaphore:
                   try:
                       console.print(f"\n[bold]Trial {trial_num}/{total_trials}: {spec['subject']}/{spec['chaos_type']}[/bold]")

                       # Get subject instance (fresh for each trial)
                       if spec["subject"] == "tikv":
                           subject = TiKVEvalSubject()
                       else:
                           raise ValueError(f"Unknown subject: {spec['subject']}")

                       trial = await run_trial(
                           subject=subject,
                           chaos_type=spec["chaos_type"] if not spec["baseline"] else "none",
                           campaign_id=campaign_id,
                           baseline=spec["baseline"],
                           operator_db_path=operator_db_path,
                           chaos_params=spec["chaos_params"],
                       )

                       trial_id = await db.insert_trial(trial)
                       console.print(f"[green]Trial {trial_id} completed[/green]")
                       completed += 1

                       # Cooldown between trials
                       if config.cooldown_seconds > 0:
                           await asyncio.sleep(config.cooldown_seconds)

                       return trial

                   except Exception as e:
                       console.print(f"[red]Trial failed: {e}[/red]")
                       failed += 1
                       return None

           # Run trials (semaphore limits concurrency)
           tasks = [
               run_single_trial(spec, i + 1)
               for i, spec in enumerate(trial_specs)
           ]
           await asyncio.gather(*tasks, return_exceptions=True)

           console.print(f"\n[bold green]Campaign {campaign_id} complete[/bold green]")
           console.print(f"Completed: {completed}, Failed: {failed}")

           return campaign_id
       ```

    4. Update existing run_trial() signature to accept chaos_params:
       ```python
       async def run_trial(
           subject: EvalSubject,
           chaos_type: str,
           campaign_id: int,
           baseline: bool = False,
           operator_db_path: Path | None = None,
           chaos_params: dict[str, Any] | None = None,
       ) -> Trial:
       ```

    5. In run_trial(), update chaos injection:
       ```python
       # Inject chaos (with params if provided)
       chaos_metadata = await subject.inject_chaos(chaos_type, **(chaos_params or {}))
       ```

    6. In run_trial(), add cleanup in finally block:
       ```python
       # After capturing final_state, before returning Trial
       try:
           if hasattr(subject, 'cleanup_chaos'):
               await subject.cleanup_chaos(chaos_metadata)
       except Exception as e:
           console.print(f"[dim]Cleanup note: {e}[/dim]")
       ```
  </action>
  <verify>
    python -c "from eval.runner.harness import run_campaign_from_config; print('run_campaign_from_config available')"
  </verify>
  <done>
    Harness supports parallel campaign execution with semaphore control, cooldown, and chaos cleanup
  </done>
</task>

<task type="auto">
  <name>Task 3: Add CLI campaign subcommand</name>
  <files>
    eval/src/eval/cli.py
  </files>
  <action>
    Add campaign subcommand to run_app typer group:

    1. Add import at top:
       ```python
       from eval.runner.campaign import load_campaign_config, CampaignConfig
       from eval.runner.harness import run_campaign_from_config
       ```

    2. Add campaign subcommand to run_app:
       ```python
       @run_app.command("campaign")
       def run_campaign_cmd(
           config_path: Path = typer.Argument(..., help="Path to campaign YAML config"),
           db_path: Path = typer.Option(
               Path("eval.db"),
               "--db",
               help="Path to eval database",
           ),
           operator_db: Optional[Path] = typer.Option(
               None,
               "--operator-db",
               help="Path to operator.db for command extraction",
           ),
       ) -> None:
           """Run a campaign from YAML configuration file.

           The config file specifies subjects, chaos types, and trial count.
           Matrix expansion generates all combinations.

           Example config:
               name: tikv-chaos-campaign
               subjects: [tikv]
               chaos_types:
                 - type: node_kill
                 - type: latency
                   params: {min_ms: 50, max_ms: 150}
                 - type: disk_pressure
                   params: {fill_percent: 80}
               trials_per_combination: 3
               parallel: 2
               cooldown_seconds: 5
               include_baseline: true

           Examples:
               eval run campaign config.yaml
               eval run campaign campaign.yaml --operator-db data/operator.db
           """
           # Validate config file exists
           if not config_path.exists():
               console.print(f"[red]Error: Config file not found: {config_path}[/red]")
               raise typer.Exit(1)

           # Load and validate config
           try:
               config = load_campaign_config(config_path)
           except Exception as e:
               console.print(f"[red]Error loading config: {e}[/red]")
               raise typer.Exit(1)

           # Show campaign summary
           console.print(f"\n[bold]Campaign: {config.name}[/bold]")
           console.print(f"Subjects: {config.subjects}")
           console.print(f"Chaos types: {[c.type for c in config.chaos_types]}")
           console.print(f"Trials per combination: {config.trials_per_combination}")
           console.print(f"Parallel: {config.parallel}")
           console.print(f"Cooldown: {config.cooldown_seconds}s")
           console.print(f"Include baseline: {config.include_baseline}")

           # Auto-detect operator.db if not specified
           if operator_db is None:
               default_operator_db = Path("data/operator.db")
               if default_operator_db.exists():
                   operator_db = default_operator_db
                   console.print(f"[dim]Using operator.db: {operator_db}[/dim]")

           # Run campaign
           async def run():
               db = EvalDB(db_path)
               await db.ensure_schema()

               return await run_campaign_from_config(
                   config=config,
                   db=db,
                   operator_db_path=operator_db,
               )

           campaign_id = asyncio.run(run())
           console.print(f"\n[bold green]Campaign {campaign_id} finished[/bold green]")
           console.print(f"Analyze with: eval analyze {campaign_id}")
       ```
  </action>
  <verify>
    cd /Users/jrtipton/x/operator/eval && uv run eval run campaign --help
  </verify>
  <done>
    CLI supports `eval run campaign config.yaml` command with proper help text and validation
  </done>
</task>

</tasks>

<verification>
1. Create a test campaign config file:
   ```yaml
   # test-campaign.yaml
   name: test-chaos-campaign
   subjects: [tikv]
   chaos_types:
     - type: node_kill
   trials_per_combination: 1
   parallel: 1
   include_baseline: false
   ```

2. Verify CLI help: `eval run campaign --help` shows usage

3. Verify config loading:
   ```python
   from eval.runner.campaign import load_campaign_config
   from pathlib import Path
   config = load_campaign_config(Path("test-campaign.yaml"))
   print(f"Loaded: {config.name}")
   ```

4. Verify matrix expansion:
   ```python
   from eval.runner.campaign import expand_campaign_matrix
   trials = expand_campaign_matrix(config)
   print(f"Generated {len(trials)} trial specs")
   ```
</verification>

<success_criteria>
- PyYAML added to eval/pyproject.toml dependencies
- CampaignConfig Pydantic model validates YAML with helpful errors
- expand_campaign_matrix() generates correct trial specs from subjects x chaos_types matrix
- run_campaign_from_config() executes trials with semaphore-controlled parallelism
- run_trial() accepts chaos_params and calls cleanup_chaos() after trial
- CLI command `eval run campaign config.yaml` loads config and runs campaign
- Failed trials are logged but campaign continues
- Cooldown between trials is respected
</success_criteria>

<output>
After completion, create `.planning/phases/38-chaos-expansion/38-02-SUMMARY.md`
</output>
