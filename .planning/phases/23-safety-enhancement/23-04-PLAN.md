---
phase: 23-safety-enhancement
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - packages/operator-core/src/operator_core/actions/session.py
  - packages/operator-core/src/operator_core/actions/safety.py
  - packages/operator-core/src/operator_core/actions/__init__.py
autonomous: true

must_haves:
  truths:
    - "Session-level risk tracking accumulates scores across actions"
    - "Risk level (LOW/MEDIUM/HIGH/CRITICAL) calculated from cumulative score"
    - "Rapid succession of actions increases risk score (frequency multiplier)"
    - "Privilege escalation patterns detected and scored"
    - "Kill switch force-terminates in-flight Docker container operations"
    - "In-flight Docker container operations are force-terminated by kill switch"
  artifacts:
    - path: "packages/operator-core/src/operator_core/actions/session.py"
      provides: "SessionRiskTracker class"
      exports: ["SessionRiskTracker", "RiskLevel"]
      contains: "calculate_risk_score"
    - path: "packages/operator-core/src/operator_core/actions/safety.py"
      provides: "Enhanced kill switch with Docker termination"
      contains: "docker kill"
  key_links:
    - from: "session.py"
      to: "risk thresholds"
      via: "RISK_THRESHOLDS dict"
      pattern: "RISK_THRESHOLDS"
    - from: "safety.py kill_switch"
      to: "subprocess"
      via: "subprocess.run for docker kill"
      pattern: "subprocess.run.*docker"
---

<objective>
Implement session-level risk tracking and enhance kill switch to terminate Docker containers.

Purpose: SAFE-07 (session risk tracking) requires detecting suspicious multi-action patterns. SAFE-08 (kill switch enhancement) requires force-terminating in-flight Docker operations since asyncio.Task.cancel() cannot interrupt blocking Docker commands.

Output: SessionRiskTracker with cumulative scoring and escalation detection; SafetyController.kill_switch() that terminates Docker containers via subprocess.
</objective>

<execution_context>
@/Users/jrtipton/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jrtipton/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/23-safety-enhancement/23-RESEARCH.md
@packages/operator-core/src/operator_core/actions/safety.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create SessionRiskTracker class</name>
  <files>packages/operator-core/src/operator_core/actions/session.py</files>
  <action>
Create new file session.py with SessionRiskTracker:

```python
"""
Session-level risk tracking for action chains (SAFE-07).

This module provides SessionRiskTracker for detecting suspicious patterns
across multiple actions in a session. Uses cumulative scoring with time-windowed
analysis to identify privilege escalation and rapid-fire action chains.

Per project patterns:
- Configurable thresholds via environment variables
- Time-windowed analysis (default 10 minutes)
- Pattern detection for escalation chains
"""

import os
from datetime import datetime, timedelta
from enum import Enum
from typing import Any


class RiskLevel(str, Enum):
    """Risk level classification for actions."""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


class SessionRiskTracker:
    """
    Track cumulative risk across action chains within a session.

    Implements behavioral analytics pattern:
    - Base risk score per action type
    - Frequency scoring (rapid succession = higher risk)
    - Pattern detection (privilege escalation chains)
    - Time-windowed accumulation

    Example:
        tracker = SessionRiskTracker("session-123")
        tracker.add_action("transfer_leader", {"region_id": 1})
        score, level = tracker.calculate_risk_score()
        if level in (RiskLevel.HIGH, RiskLevel.CRITICAL):
            # Require elevated approval
            pass
    """

    # Base risk scores for action types
    # Lower is safer, higher is riskier
    ACTION_RISK_SCORES: dict[str, int] = {
        # TiKV actions
        "transfer_leader": 3,
        "add_peer": 5,
        "remove_peer": 7,
        # Docker actions (Phase 24)
        "docker_inspect": 1,
        "docker_logs": 1,
        "docker_start": 4,
        "docker_restart": 4,
        "docker_stop": 6,
        "docker_kill": 8,
        "docker_exec": 8,
        "docker_network_connect": 5,
        "docker_network_disconnect": 6,
        # Host actions (Phase 25)
        "host_service_start": 4,
        "host_service_stop": 6,
        "host_service_restart": 5,
        "host_kill_process": 7,
        # Script execution (Phase 26)
        "execute_script": 10,
    }

    # Default risk score for unknown actions
    DEFAULT_RISK_SCORE = 2

    # Risk level thresholds
    RISK_THRESHOLDS: dict[RiskLevel, int] = {
        RiskLevel.LOW: 0,
        RiskLevel.MEDIUM: 10,
        RiskLevel.HIGH: 20,
        RiskLevel.CRITICAL: 35,
    }

    def __init__(
        self,
        session_id: str,
        window_minutes: int | None = None,
    ) -> None:
        """
        Initialize session risk tracker.

        Args:
            session_id: Unique identifier for this session
            window_minutes: Time window for risk accumulation (default from env or 10)
        """
        self.session_id = session_id

        # Read window from env or use default
        if window_minutes is None:
            window_minutes = int(os.environ.get("OPERATOR_RISK_WINDOW_MINUTES", "10"))
        self.window = timedelta(minutes=window_minutes)

        self.action_history: list[dict[str, Any]] = []

    def add_action(
        self,
        action_name: str,
        parameters: dict[str, Any] | None = None,
        timestamp: datetime | None = None,
    ) -> None:
        """
        Record action in session history.

        Args:
            action_name: Name of the action executed
            parameters: Action parameters (for pattern detection)
            timestamp: When action occurred (default: now)
        """
        if timestamp is None:
            timestamp = datetime.now()

        self.action_history.append({
            "action_name": action_name,
            "parameters": parameters or {},
            "timestamp": timestamp,
        })

    def calculate_risk_score(self) -> tuple[int, RiskLevel]:
        """
        Calculate cumulative risk score for current session.

        Returns:
            Tuple of (score, level)
        """
        now = datetime.now()
        cutoff = now - self.window

        # Filter to time window
        recent_actions = [
            a for a in self.action_history
            if a["timestamp"] >= cutoff
        ]

        if not recent_actions:
            return (0, RiskLevel.LOW)

        # Base score: sum of action risks
        base_score = sum(
            self.ACTION_RISK_SCORES.get(a["action_name"], self.DEFAULT_RISK_SCORE)
            for a in recent_actions
        )

        # Frequency multiplier (more than 3 actions in window = suspicious)
        if len(recent_actions) > 5:
            frequency_multiplier = 2.0
        elif len(recent_actions) > 3:
            frequency_multiplier = 1.5
        else:
            frequency_multiplier = 1.0

        # Pattern detection: escalation chains
        escalation_bonus = self._detect_escalation_chain(recent_actions)

        total_score = int(base_score * frequency_multiplier) + escalation_bonus

        # Determine risk level
        level = RiskLevel.LOW
        for threshold_level in [RiskLevel.CRITICAL, RiskLevel.HIGH, RiskLevel.MEDIUM]:
            if total_score >= self.RISK_THRESHOLDS[threshold_level]:
                level = threshold_level
                break

        return (total_score, level)

    def _detect_escalation_chain(self, actions: list[dict[str, Any]]) -> int:
        """
        Detect privilege escalation patterns.

        Patterns detected:
        - exec_command following container restart = +10 risk
        - Multiple remove_peer actions = +5 risk per additional
        - Script execution after docker operations = +15 risk

        Args:
            actions: List of recent actions

        Returns:
            Bonus risk score from pattern detection
        """
        bonus = 0
        action_names = [a["action_name"] for a in actions]

        # Check for exec after restart/start (container compromise pattern)
        for i in range(len(action_names) - 1):
            if action_names[i] in ("docker_restart", "docker_start"):
                if action_names[i + 1] in ("docker_exec", "execute_script"):
                    bonus += 10

        # Check for repeated destructive actions
        destructive_actions = ["remove_peer", "docker_stop", "docker_kill", "host_kill_process"]
        for action in destructive_actions:
            count = action_names.count(action)
            if count > 1:
                bonus += 5 * (count - 1)

        # Check for script execution after docker operations
        docker_ops = {"docker_start", "docker_stop", "docker_restart", "docker_exec"}
        has_docker_op = any(name in docker_ops for name in action_names)
        has_script = "execute_script" in action_names
        if has_docker_op and has_script:
            bonus += 15

        return bonus

    def requires_elevated_approval(self) -> bool:
        """
        Determine if current risk requires additional approval.

        Returns:
            True if risk level is HIGH or CRITICAL
        """
        _, level = self.calculate_risk_score()
        return level in (RiskLevel.HIGH, RiskLevel.CRITICAL)

    def get_risk_summary(self) -> dict[str, Any]:
        """
        Get a summary of current session risk state.

        Returns:
            Dict with score, level, action_count, and detected patterns
        """
        score, level = self.calculate_risk_score()

        now = datetime.now()
        cutoff = now - self.window
        recent_count = len([a for a in self.action_history if a["timestamp"] >= cutoff])

        return {
            "session_id": self.session_id,
            "score": score,
            "level": level.value,
            "action_count": recent_count,
            "window_minutes": self.window.total_seconds() / 60,
            "requires_elevated_approval": self.requires_elevated_approval(),
        }

    def clear_history(self) -> None:
        """Clear action history (use with caution)."""
        self.action_history.clear()
```
  </action>
  <verify>
Run: `cd /Users/jrtipton/x/operator/packages/operator-core && python -c "
from operator_core.actions.session import SessionRiskTracker, RiskLevel

# Test basic scoring
tracker = SessionRiskTracker('test-session')
tracker.add_action('transfer_leader', {'region_id': 1})
score, level = tracker.calculate_risk_score()
print(f'Single action: score={score}, level={level.value}')
assert score == 3  # transfer_leader base score
assert level == RiskLevel.LOW

# Test accumulation
for i in range(4):
    tracker.add_action('remove_peer', {'store_id': i})

score, level = tracker.calculate_risk_score()
print(f'After 4 remove_peer: score={score}, level={level.value}')
assert level in (RiskLevel.MEDIUM, RiskLevel.HIGH)  # Should escalate

# Test escalation pattern detection
tracker2 = SessionRiskTracker('test-session-2')
tracker2.add_action('docker_restart', {})
tracker2.add_action('docker_exec', {'command': 'bash'})
score2, level2 = tracker2.calculate_risk_score()
print(f'Restart+exec pattern: score={score2}, level={level2.value}')
assert score2 > 12  # Base 4+8 plus pattern bonus

print('All SessionRiskTracker tests PASS')
"`
  </verify>
  <done>SessionRiskTracker tracks cumulative risk with time-windowed analysis and pattern detection.</done>
</task>

<task type="auto">
  <name>Task 2: Enhance kill switch with Docker termination</name>
  <files>packages/operator-core/src/operator_core/actions/safety.py</files>
  <action>
Modify SafetyController.kill_switch() to force-terminate Docker containers:

1. Add subprocess import at top of file:
   ```python
   import subprocess
   import asyncio
   ```

2. Add Docker termination helper method:
   ```python
   def _force_kill_docker_containers(self) -> int:
       """
       Force-kill all operator-managed Docker containers.

       CRITICAL: asyncio.Task.cancel() cannot interrupt blocking
       subprocess calls or force Docker to stop. We must use
       subprocess.run() with 'docker kill' command.

       Returns:
           Number of containers killed
       """
       try:
           # Find operator-managed containers (labeled with operator.managed=true)
           result = subprocess.run(
               [
                   'docker', 'ps', '-q',
                   '--filter', 'label=operator.managed=true',
                   '--filter', 'status=running'
               ],
               capture_output=True,
               text=True,
               timeout=5
           )

           if result.returncode != 0:
               return 0

           container_ids = result.stdout.strip().split('\n')
           container_ids = [cid for cid in container_ids if cid]

           if not container_ids:
               return 0

           # Force kill all containers (SIGKILL, exit code 137)
           kill_result = subprocess.run(
               ['docker', 'kill'] + container_ids,
               capture_output=True,
               text=True,
               timeout=30
           )

           # Log any errors but don't raise - best effort termination
           if kill_result.returncode != 0:
               # Could log to auditor here if needed
               pass

           return len(container_ids)

       except subprocess.TimeoutExpired:
           # Docker command timed out - containers may still be running
           return 0
       except FileNotFoundError:
           # Docker not installed - skip container termination
           return 0
       except Exception:
           # Any other error - skip container termination
           return 0
   ```

3. Add asyncio task cancellation helper:
   ```python
   async def _cancel_operator_tasks(self) -> int:
       """Cancel all operator-created asyncio tasks."""
       cancelled = 0
       for task in asyncio.all_tasks():
           if not task.done() and task.get_name().startswith('operator-'):
               task.cancel()
               cancelled += 1

       return cancelled
   ```

4. Update kill_switch() to return detailed results:
   ```python
   async def kill_switch(self) -> dict[str, int]:
       """
       Emergency stop - cancel all pending actions, kill containers, switch to observe mode (SAF-01, SAFE-08).

       This is the emergency stop button:
       1. Cancels ALL pending (proposed/validated) proposals
       2. Force-kills Docker containers with operator.managed=true label
       3. Cancels operator-created asyncio tasks
       4. Switches mode to OBSERVE
       5. Logs kill_switch event with counts

       Returns:
           Dict with counts: pending_proposals, docker_containers, asyncio_tasks
       """
       results = {
           "pending_proposals": 0,
           "docker_containers": 0,
           "asyncio_tasks": 0,
       }

       # 1. Cancel all pending proposals
       from operator_core.db.actions import ActionDB
       async with ActionDB(self.db_path) as db:
           results["pending_proposals"] = await db.cancel_all_pending()

       # 2. Force-kill Docker containers (SAFE-08)
       # This MUST use subprocess, not asyncio - asyncio cannot force-kill blocking operations
       results["docker_containers"] = self._force_kill_docker_containers()

       # 3. Cancel asyncio tasks
       results["asyncio_tasks"] = await self._cancel_operator_tasks()

       # 4. Switch to observe mode
       self._mode = SafetyMode.OBSERVE

       # 5. Log kill switch activation with all counts
       await self._auditor.log_kill_switch(
           cancelled_count=results["pending_proposals"],
           docker_killed=results["docker_containers"],
           tasks_cancelled=results["asyncio_tasks"],
       )

       return results
   ```

5. Update ActionAuditor.log_kill_switch() signature to accept additional counts:
   In audit.py, update the method (if not already done):
   ```python
   async def log_kill_switch(
       self,
       cancelled_count: int,
       docker_killed: int = 0,
       tasks_cancelled: int = 0,
   ) -> None:
       await self.log_event(AuditEvent(
           proposal_id=None,
           event_type="kill_switch",
           event_data={
               "cancelled_count": cancelled_count,
               "docker_killed": docker_killed,
               "tasks_cancelled": tasks_cancelled,
           },
           actor="system",
           timestamp=datetime.now(),
       ))
   ```
  </action>
  <verify>
Run: `cd /Users/jrtipton/x/operator/packages/operator-core && python -c "
import asyncio
from pathlib import Path
import tempfile
from operator_core.actions.safety import SafetyController, SafetyMode
from operator_core.actions.audit import ActionAuditor

async def test():
    with tempfile.TemporaryDirectory() as tmp:
        db_path = Path(tmp) / 'test.db'
        auditor = ActionAuditor(db_path)
        safety = SafetyController(db_path, auditor, mode=SafetyMode.EXECUTE)

        # Test kill switch returns dict with expected keys
        results = await safety.kill_switch()
        print(f'Kill switch results: {results}')

        assert 'pending_proposals' in results
        assert 'docker_containers' in results
        assert 'asyncio_tasks' in results
        assert safety.mode == SafetyMode.OBSERVE
        print('Kill switch returns detailed results: PASS')

        # Check audit log
        events = await auditor.get_events(event_type='kill_switch')
        assert len(events) == 1
        event = events[0]
        assert 'docker_killed' in event.event_data
        print('Kill switch logged with Docker count: PASS')

asyncio.run(test())
"`
  </verify>
  <done>Kill switch force-terminates Docker containers via subprocess and returns detailed results.</done>
</task>

<task type="auto">
  <name>Task 3: Export new classes and run tests</name>
  <files>packages/operator-core/src/operator_core/actions/__init__.py</files>
  <action>
Update actions/__init__.py to export SessionRiskTracker and RiskLevel:

```python
from operator_core.actions.session import RiskLevel, SessionRiskTracker
```

Add them to __all__ if there is one, or ensure they're importable.

Also update audit.py log_kill_switch if not done in Task 2.

Then run the full test suite to verify no regressions.
  </action>
  <verify>
Run: `cd /Users/jrtipton/x/operator/packages/operator-core && python -c "
from operator_core.actions.session import SessionRiskTracker, RiskLevel
from operator_core.actions.safety import SafetyController, SafetyMode
print('Imports work: PASS')
"` && `cd /Users/jrtipton/x/operator/packages/operator-core && python -m pytest tests/ -v --tb=short 2>&1 | tail -30`
  </verify>
  <done>SessionRiskTracker and RiskLevel exported; all tests pass.</done>
</task>

</tasks>

<verification>
1. SessionRiskTracker accumulates risk scores across actions
2. Risk level thresholds correctly classify LOW/MEDIUM/HIGH/CRITICAL
3. Frequency multiplier increases score for rapid actions
4. Escalation patterns detected and scored (restart+exec, repeated destructive)
5. Kill switch calls docker kill via subprocess
6. Kill switch returns dict with pending_proposals, docker_containers, asyncio_tasks
7. Audit log includes docker_killed count
</verification>

<success_criteria>
- SessionRiskTracker correctly identifies high-risk action patterns
- Kill switch terminates Docker containers (verified with mock or real containers)
- Kill switch audit log shows container termination count
- All existing tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/23-safety-enhancement/23-04-SUMMARY.md`
</output>
