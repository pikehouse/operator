---
phase: 15-workflow-actions
plan: 03
type: execute
wave: 2
depends_on: ["15-01"]
files_modified:
  - packages/operator-core/pyproject.toml
  - packages/operator-core/src/operator_core/actions/retry.py
  - packages/operator-core/src/operator_core/actions/executor.py
  - packages/operator-core/src/operator_core/actions/__init__.py
autonomous: true

must_haves:
  truths:
    - "Retry configuration calculates exponential backoff with jitter"
    - "Executor can propose multi-action workflows"
    - "Executor can schedule next retry for failed actions"
  artifacts:
    - path: "packages/operator-core/src/operator_core/actions/retry.py"
      provides: "RetryConfig with exponential backoff calculation"
      contains: "class RetryConfig"
    - path: "packages/operator-core/src/operator_core/actions/executor.py"
      provides: "Workflow proposal and retry scheduling"
      contains: "propose_workflow"
  key_links:
    - from: "actions/retry.py"
      to: "actions/executor.py"
      via: "RetryConfig used in schedule_next_retry"
      pattern: "RetryConfig|calculate_next_retry"
---

<objective>
Add retry configuration module and extend ActionExecutor with workflow proposal and retry scheduling methods.

Purpose: This plan adds tenacity as a dependency (for future use in execute_with_retry), creates the RetryConfig class for exponential backoff calculation, and extends ActionExecutor to support proposing multi-action workflows and scheduling retry attempts. The agent runner will use these methods in Plan 04.

Output: retry.py module with RetryConfig, extended executor with propose_workflow and schedule_next_retry methods.
</objective>

<execution_context>
@/Users/jrtipton/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jrtipton/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/15-workflow-actions/15-RESEARCH.md
@packages/operator-core/pyproject.toml
@packages/operator-core/src/operator_core/actions/executor.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add tenacity dependency and create retry configuration module</name>
  <files>packages/operator-core/pyproject.toml, packages/operator-core/src/operator_core/actions/retry.py, packages/operator-core/src/operator_core/actions/__init__.py</files>
  <action>
Add tenacity to pyproject.toml dependencies:

```toml
dependencies = [
    "typer>=0.21.0",
    "rich>=14.0.0",
    "python-on-whales>=0.70.0",
    "httpx>=0.27.0",
    "pydantic>=2.0.0",
    "aiosqlite>=0.20.0",
    "anthropic>=0.40.0",
    "readchar>=4.2.0",
    "sparklines>=0.4.2",
    "tenacity>=8.2.0",
]
```

Create packages/operator-core/src/operator_core/actions/retry.py:

```python
"""
Retry configuration for action execution with exponential backoff.

This module provides RetryConfig for calculating retry delays with
exponential backoff and jitter, preventing thundering herd problems
when multiple failed actions retry simultaneously.

Per RESEARCH.md:
- Use exponential backoff with jitter
- Cap max_retries to prevent infinite loops
- Persist retry state in database for restart recovery
"""

import random
from dataclasses import dataclass
from datetime import datetime, timedelta


@dataclass
class RetryConfig:
    """
    Configuration for action retry behavior.

    Uses exponential backoff with jitter to spread out retry attempts
    and prevent overwhelming the target system.

    Attributes:
        max_attempts: Maximum number of retry attempts (default 3)
        min_wait_seconds: Minimum wait before first retry (default 1.0)
        max_wait_seconds: Maximum wait between retries (default 60.0)
        exponential_base: Base for exponential calculation (default 2.0)
        jitter_fraction: Fraction of wait time to add as jitter (default 0.5)

    Example:
        config = RetryConfig(max_attempts=5, min_wait_seconds=2.0)
        next_retry = config.calculate_next_retry(attempt=1)
        # Returns datetime ~2-3 seconds from now (2s base + jitter)
    """

    max_attempts: int = 3
    min_wait_seconds: float = 1.0
    max_wait_seconds: float = 60.0
    exponential_base: float = 2.0
    jitter_fraction: float = 0.5

    def calculate_next_retry(self, attempt: int) -> datetime:
        """
        Calculate the next retry time with exponential backoff + jitter.

        Formula: min(max_wait, min_wait * base^attempt) + random(0, wait * jitter)

        Args:
            attempt: The attempt number (0 for first retry, 1 for second, etc.)

        Returns:
            datetime when the next retry should occur
        """
        # Calculate base wait with exponential backoff
        wait = min(
            self.max_wait_seconds,
            self.min_wait_seconds * (self.exponential_base ** attempt),
        )

        # Add jitter to prevent thundering herd
        jitter = random.uniform(0, wait * self.jitter_fraction)
        delay = wait + jitter

        return datetime.now() + timedelta(seconds=delay)

    def should_retry(self, retry_count: int) -> bool:
        """
        Check if another retry attempt should be made.

        Args:
            retry_count: Current number of attempts made

        Returns:
            True if retry_count < max_attempts, False otherwise
        """
        return retry_count < self.max_attempts
```

Add RetryConfig to actions/__init__.py exports:

```python
from operator_core.actions.retry import RetryConfig
```
  </action>
  <verify>python -c "
from operator_core.actions.retry import RetryConfig
from datetime import datetime

config = RetryConfig(max_attempts=3, min_wait_seconds=1.0)

# Test backoff calculation
for attempt in range(3):
    next_retry = config.calculate_next_retry(attempt)
    delay = (next_retry - datetime.now()).total_seconds()
    print(f'Attempt {attempt}: retry in {delay:.1f}s')

# Test should_retry
print(f'Should retry at 0: {config.should_retry(0)}')
print(f'Should retry at 3: {config.should_retry(3)}')
"</verify>
  <done>tenacity added to pyproject.toml. retry.py created with RetryConfig class including calculate_next_retry (exponential backoff + jitter) and should_retry methods. RetryConfig exported from actions/__init__.py.</done>
</task>

<task type="auto">
  <name>Task 2: Add workflow proposal method to ActionExecutor</name>
  <files>packages/operator-core/src/operator_core/actions/executor.py</files>
  <action>
Add imports at top (inside TYPE_CHECKING block):

```python
if TYPE_CHECKING:
    from operator_core.agent.diagnosis import ActionRecommendation, WorkflowRecommendation
    from operator_core.db.actions import ActionDB
    from operator_core.subject import Subject
```

Note: WorkflowRecommendation will be defined later; for now we can use inline type hint.

Add propose_workflow method to ActionExecutor (after propose_action):

```python
async def propose_workflow(
    self,
    name: str,
    description: str,
    action_recommendations: list["ActionRecommendation"],
    ticket_id: int | None = None,
) -> int:
    """
    Create a workflow proposal from multiple action recommendations.

    Validates all actions exist and parameters are valid before
    creating the workflow. All actions in a workflow share approval
    (approve workflow = approve all actions).

    Args:
        name: Workflow name (e.g., "drain_and_verify")
        description: What this workflow accomplishes
        action_recommendations: List of ActionRecommendations to include
        ticket_id: Optional ticket ID for traceability

    Returns:
        Created workflow ID

    Raises:
        ObserveOnlyError: If safety mode is OBSERVE
        ValueError: If any action not found in registry
        ValidationError: If any action parameters fail validation
    """
    # Check safety - proposals blocked in observe mode
    self._safety.check_can_execute()

    if not action_recommendations:
        raise ValueError("Workflow must contain at least one action")

    # Validate all actions exist and parameters are valid
    for rec in action_recommendations:
        definition = self._registry.get_definition(rec.action_name)
        if definition is None:
            raise ValueError(
                f"Unknown action '{rec.action_name}' in workflow. "
                f"Available actions: {self._registry.list_action_names()}"
            )
        validate_action_params(definition, rec.parameters)

    # Create proposals from recommendations
    proposals = [
        ActionProposal(
            ticket_id=ticket_id,
            action_name=rec.action_name,
            action_type=ActionType.SUBJECT,
            parameters=rec.parameters,
            reason=rec.reason,
            status=ActionStatus.PROPOSED,
            proposed_at=datetime.now(),
            proposed_by="agent",
        )
        for rec in action_recommendations
    ]

    # Create workflow in database
    from operator_core.db.actions import ActionDB

    async with ActionDB(self.db_path) as db:
        workflow_id = await db.create_workflow(
            name=name,
            description=description,
            actions=proposals,
            ticket_id=ticket_id,
        )

    # Log workflow created
    await self._auditor.log_event(
        proposal_id=None,
        event_type="workflow_created",
        event_data={
            "workflow_id": workflow_id,
            "name": name,
            "action_count": len(proposals),
        },
        actor="agent",
    )

    return workflow_id
```
  </action>
  <verify>python -c "
# Just verify the method exists and has correct signature
from operator_core.actions.executor import ActionExecutor
import inspect

sig = inspect.signature(ActionExecutor.propose_workflow)
params = list(sig.parameters.keys())
print(f'propose_workflow params: {params}')
assert 'name' in params
assert 'action_recommendations' in params
print('propose_workflow method exists with correct signature')
"</verify>
  <done>ActionExecutor has propose_workflow method that validates all actions, creates ActionProposals, and creates workflow in database with audit logging.</done>
</task>

<task type="auto">
  <name>Task 3: Add retry scheduling method to ActionExecutor</name>
  <files>packages/operator-core/src/operator_core/actions/executor.py</files>
  <action>
Add RetryConfig import at top:

```python
from operator_core.actions.retry import RetryConfig
```

Add retry_config parameter to __init__ (after approval_mode):

```python
def __init__(
    self,
    db_path: Path,
    registry: ActionRegistry,
    safety: SafetyController,
    auditor: ActionAuditor,
    approval_mode: bool | None = None,
    retry_config: RetryConfig | None = None,
) -> None:
    """
    Initialize the action executor.

    Args:
        db_path: Path to SQLite database
        registry: ActionRegistry for action discovery and validation
        safety: SafetyController for execution gating
        auditor: ActionAuditor for lifecycle logging
        approval_mode: If True, require approval before execution.
                       If None, read from OPERATOR_APPROVAL_MODE env var.
                       Default is False (autonomous execution).
        retry_config: Configuration for retry behavior. If None, uses defaults.
    """
    self.db_path = db_path
    self._registry = registry
    self._safety = safety
    self._auditor = auditor
    self._retry_config = retry_config or RetryConfig()

    # Resolve approval mode from parameter or environment
    if approval_mode is None:
        self._approval_mode = (
            os.environ.get("OPERATOR_APPROVAL_MODE", "false").lower() == "true"
        )
    else:
        self._approval_mode = approval_mode
```

Add schedule_next_retry method (after execute_proposal):

```python
async def schedule_next_retry(
    self,
    proposal_id: int,
    error_message: str,
) -> datetime | None:
    """
    Schedule the next retry attempt for a failed action.

    Uses exponential backoff with jitter to calculate the next retry time.
    If max retries exceeded, returns None and logs final failure.

    Args:
        proposal_id: ID of the failed proposal
        error_message: Error message from the failed attempt

    Returns:
        datetime of next retry, or None if max retries exceeded
    """
    from operator_core.db.actions import ActionDB

    async with ActionDB(self.db_path) as db:
        proposal = await db.get_proposal(proposal_id)

        if proposal is None:
            raise ValueError(f"Proposal {proposal_id} not found")

        # Increment retry count and record error
        await db.increment_retry_count(proposal_id, error_message)

        # Check if more retries allowed
        new_retry_count = proposal.retry_count + 1
        if not self._retry_config.should_retry(new_retry_count):
            # Max retries exceeded
            await self._auditor.log_event(
                proposal_id=proposal_id,
                event_type="retry_exhausted",
                event_data={
                    "retry_count": new_retry_count,
                    "max_retries": proposal.max_retries,
                    "last_error": error_message,
                },
                actor="system",
            )
            return None

        # Calculate next retry time
        next_retry = self._retry_config.calculate_next_retry(new_retry_count)
        await db.update_next_retry(proposal_id, next_retry)

        # Log retry scheduled
        await self._auditor.log_event(
            proposal_id=proposal_id,
            event_type="retry_scheduled",
            event_data={
                "retry_count": new_retry_count,
                "next_retry_at": next_retry.isoformat(),
            },
            actor="system",
        )

        return next_retry
```
  </action>
  <verify>python -c "
from operator_core.actions.executor import ActionExecutor
import inspect

# Check __init__ has retry_config param
init_sig = inspect.signature(ActionExecutor.__init__)
assert 'retry_config' in init_sig.parameters
print('__init__ has retry_config parameter')

# Check schedule_next_retry exists
assert hasattr(ActionExecutor, 'schedule_next_retry')
retry_sig = inspect.signature(ActionExecutor.schedule_next_retry)
assert 'proposal_id' in retry_sig.parameters
assert 'error_message' in retry_sig.parameters
print('schedule_next_retry method exists with correct signature')
"</verify>
  <done>ActionExecutor has retry_config parameter in __init__ with default RetryConfig. schedule_next_retry method calculates exponential backoff, updates database, and logs retry scheduling or exhaustion.</done>
</task>

</tasks>

<verification>
1. tenacity in pyproject.toml: `grep tenacity packages/operator-core/pyproject.toml`
2. RetryConfig calculates backoff: Test with different attempt numbers
3. propose_workflow validates actions: Test with invalid action name
4. schedule_next_retry calculates delay: Test returns datetime in future
5. Exports work: `python -c "from operator_core.actions import RetryConfig"`
</verification>

<success_criteria>
1. tenacity>=8.2.0 in pyproject.toml dependencies
2. RetryConfig class with max_attempts, min_wait_seconds, max_wait_seconds, exponential_base, jitter_fraction
3. calculate_next_retry returns datetime with exponential backoff + jitter
4. should_retry returns True when retry_count < max_attempts
5. propose_workflow validates all actions before creating workflow
6. propose_workflow creates workflow in database with linked proposals
7. ActionExecutor.__init__ accepts optional retry_config parameter
8. schedule_next_retry increments retry_count and schedules next attempt
9. schedule_next_retry returns None when max_retries exceeded
10. All methods log appropriate audit events
</success_criteria>

<output>
After completion, create `.planning/phases/15-workflow-actions/15-03-SUMMARY.md`
</output>
